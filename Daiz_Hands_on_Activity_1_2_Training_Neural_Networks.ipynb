{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chichi213/Daiz_CPE-313/blob/main/Daiz_Hands_on_Activity_1_2_Training_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = pd.read_csv(\"/content/drive/MyDrive/pima-indians-diabetes.csv\")\n",
        "filepath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "X_TJxdp46iVY",
        "outputId": "1aa66e40-49cf-4fe9-b081-6af8272b3d0e"
      },
      "id": "X_TJxdp46iVY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      6  148  72  35    0  33.6  0.627  50  1\n",
              "0     1   85  66  29    0  26.6  0.351  31  0\n",
              "1     8  183  64   0    0  23.3  0.672  32  1\n",
              "2     1   89  66  23   94  28.1  0.167  21  0\n",
              "3     0  137  40  35  168  43.1  2.288  33  1\n",
              "4     5  116  74   0    0  25.6  0.201  30  0\n",
              "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
              "762  10  101  76  48  180  32.9  0.171  63  0\n",
              "763   2  122  70  27    0  36.8  0.340  27  0\n",
              "764   5  121  72  23  112  26.2  0.245  30  0\n",
              "765   1  126  60   0    0  30.1  0.349  47  1\n",
              "766   1   93  70  31    0  30.4  0.315  23  0\n",
              "\n",
              "[767 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23b680bd-4f5a-4fc9-8989-b51ce8bd8303\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>148</th>\n",
              "      <th>72</th>\n",
              "      <th>35</th>\n",
              "      <th>0</th>\n",
              "      <th>33.6</th>\n",
              "      <th>0.627</th>\n",
              "      <th>50</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>767 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b680bd-4f5a-4fc9-8989-b51ce8bd8303')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23b680bd-4f5a-4fc9-8989-b51ce8bd8303 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23b680bd-4f5a-4fc9-8989-b51ce8bd8303');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d79d6c81-b816-4417-ba13-93a5ba5d1cf5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d79d6c81-b816-4417-ba13-93a5ba5d1cf5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d79d6c81-b816-4417-ba13-93a5ba5d1cf5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "abb6a554-93f6-44b4-9a5d-c1ce7d83e91c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "533               6                      91               0               0   \n",
              "167               4                     120              68               0   \n",
              "446               1                     100              72              12   \n",
              "308               0                     128              68              19   \n",
              "735               4                      95              60              32   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "533        0  29.8              0.501   31             0  \n",
              "167        0  29.6              0.709   34             0  \n",
              "446       70  25.3              0.658   28             0  \n",
              "308      180  30.5              1.391   25             1  \n",
              "735        0  35.4              0.284   28             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-080b504a-630f-4d3c-91e7-9be11e39e8c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>6</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.8</td>\n",
              "      <td>0.501</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.709</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>72</td>\n",
              "      <td>12</td>\n",
              "      <td>70</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.658</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>68</td>\n",
              "      <td>19</td>\n",
              "      <td>180</td>\n",
              "      <td>30.5</td>\n",
              "      <td>1.391</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>60</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>35.4</td>\n",
              "      <td>0.284</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-080b504a-630f-4d3c-91e7-9be11e39e8c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-080b504a-630f-4d3c-91e7-9be11e39e8c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-080b504a-630f-4d3c-91e7-9be11e39e8c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a30d1a34-4367-4e53-8db0-8aca3315942f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a30d1a34-4367-4e53-8db0-8aca3315942f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a30d1a34-4367-4e53-8db0-8aca3315942f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d674e435-7f3b-46d3-fc23-91dc05872890"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2615e934-d0c3-4667-dab6-111b11032159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d1cdb5-7dd5-4558-fb55-fb2c96128124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520b98b5-ffdd-4cc9-989a-ffc05b4a3b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6199 - accuracy: 0.6684 - val_loss: 0.6096 - val_accuracy: 0.6458\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6788 - val_loss: 0.5926 - val_accuracy: 0.6615\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6997 - val_loss: 0.5791 - val_accuracy: 0.6458\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7101 - val_loss: 0.5682 - val_accuracy: 0.6667\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7170 - val_loss: 0.5593 - val_accuracy: 0.6875\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7274 - val_loss: 0.5520 - val_accuracy: 0.6823\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7326 - val_loss: 0.5458 - val_accuracy: 0.6875\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7448 - val_loss: 0.5406 - val_accuracy: 0.6979\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7361 - val_loss: 0.5362 - val_accuracy: 0.7031\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7413 - val_loss: 0.5324 - val_accuracy: 0.7135\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7500 - val_loss: 0.5291 - val_accuracy: 0.7292\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7535 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7517 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7552 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7587 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7569 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7604 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7674 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7691 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7674 - val_loss: 0.5082 - val_accuracy: 0.7344\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7708 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7674 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7448\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7656 - val_loss: 0.5006 - val_accuracy: 0.7448\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7448\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7674 - val_loss: 0.4992 - val_accuracy: 0.7448\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7674 - val_loss: 0.4986 - val_accuracy: 0.7448\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7448\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7639 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7639 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7639 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7656 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7639 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7639 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7639 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7778 - val_loss: 0.4899 - val_accuracy: 0.7500\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7448\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7448\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7448\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7448\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7448\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7448\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7448\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7448\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4882 - val_accuracy: 0.7448\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4881 - val_accuracy: 0.7448\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7448\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7448\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7344\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7344\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7344\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7344\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7812 - val_loss: 0.4876 - val_accuracy: 0.7344\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.4876 - val_accuracy: 0.7396\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7396\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7396\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7396\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7396\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7396\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7396\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7396\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7396\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7396\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7396\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7396\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7865 - val_loss: 0.4884 - val_accuracy: 0.7396\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7396\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7396\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7448\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7865 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7448\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7448\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7448\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7396\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.4890 - val_accuracy: 0.7396\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7396\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7396\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7795 - val_loss: 0.4891 - val_accuracy: 0.7396\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7396\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7396\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7396\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7396\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.4892 - val_accuracy: 0.7396\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7396\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.4893 - val_accuracy: 0.7396\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7396\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.4894 - val_accuracy: 0.7396\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7396\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.4894 - val_accuracy: 0.7396\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7396\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7396\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.4896 - val_accuracy: 0.7396\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7396\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7396\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7396\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.4897 - val_accuracy: 0.7396\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7396\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7396\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7396\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7396\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.4898 - val_accuracy: 0.7396\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7396\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7396\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7396\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.4900 - val_accuracy: 0.7396\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.4901 - val_accuracy: 0.7396\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.4902 - val_accuracy: 0.7448\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.7448\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7448\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7865 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.4907 - val_accuracy: 0.7552\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_x=model.predict(X_test)\n",
        "classes_x=np.argmax(predict_x,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68oH2SEe8Cpa",
        "outputId": "33c11087-8ce8-4020-c082-56c220c15c77"
      },
      "id": "68oH2SEe8Cpa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF20S3_-O6Vi",
        "outputId": "a9a75a8f-e98d-4610-fe08-de9aae5f636b"
      },
      "id": "uF20S3_-O6Vi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n",
            "6/6 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d31550-4f69-4440-e817-c603815418d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bcfaa6a-ac10-4d34-849f-4aa754f15761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54680055],\n",
              "       [0.55935943],\n",
              "       [0.3156624 ],\n",
              "       [0.29256752],\n",
              "       [0.14578478],\n",
              "       [0.52783585],\n",
              "       [0.03926913],\n",
              "       [0.35361868],\n",
              "       [0.94557095],\n",
              "       [0.25678018]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "3212efce-918b-487c-d22a-50a731002717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.755\n",
            "roc-auc is 0.825\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABum0lEQVR4nO3deVyU5f7/8TcgiwMilrhmbi1mdrQ0PQamlUplnjxl4pJbppbaRmVuaWqGZZotruWSC4J5rKw8KmmeMi3LpazUXLNSUHNBQWCA6/dHX+Ynssh+z/J6Ph48am7ue+YzXDPy5nPd9zVexhgjAAAAwCLeVhcAAAAAz0YgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFkK8pU6aoQYMG8vHxUbNmzawuB06kX79+qlevXo5tXl5eeumll4p8XwsXLpSXl5e+//770inOg7Rr105NmjS57H6HDx+Wl5eXFi5cWPZFAcVAIIXTyv4llf1VoUIF1a5dW/369dOff/6Z5zHGGC1evFi33367QkJCZLPZdNNNN2nChAlKTk7O97E+/PBD3XPPPapatar8/PxUq1YtdevWTRs2bChUrampqXrjjTfUqlUrVa5cWQEBAbruuus0bNgw/frrr8V6/lZbt26dhg8frrCwMC1YsECvvPJKmT5ev3795OXlpX/84x/K6xONvby8NGzYMMft7F+wXl5e+s9//pNr/5deekleXl46efJkmdZdWNn1ZH/ZbDY1btxYY8aMUVJSkmO/vMJZ9rHe3t76/fffc913UlKSKlasmOtndLHdu3fLy8tLAQEBOnPmTKk/P2ezevXqYoVjANaoYHUBwOVMmDBB9evXV2pqqr755hstXLhQmzZt0k8//aSAgADHfpmZmerZs6eWL1+uNm3a6KWXXpLNZtNXX32l8ePH64MPPtDnn3+u6tWrO44xxuiRRx7RwoULdfPNNysqKko1atTQsWPH9OGHH+quu+7S119/rdtuuy3f+k6ePKm7775b27Zt03333aeePXsqKChIe/fuVWxsrObOnav09PQy/RmVhQ0bNsjb21vz5s2Tn59fuT3url27tHLlSj344IOFPmbChAl64IEH5OXlVYaVlY5Zs2YpKChI58+f17p16zRp0iRt2LBBX3/99WXr9/f317JlyzR8+PAc21euXHnZx12yZIlq1Kih06dPa8WKFXr00UdL9DzycuHCBVWo4By/VlavXq0ZM2YQSgEX4Rz/cgAFuOeee9SiRQtJ0qOPPqqqVavq1Vdf1apVq9StWzfHfq+99pqWL1+u5557TlOmTHFsHzRokLp166YuXbqoX79++u9//+v43tSpU7Vw4UI9/fTTmjZtWo5AMHr0aC1evPiyv2D79eunHTt2aMWKFblC1MSJEzV69OgSPf9sGRkZysrKKrdwePz4cVWsWLHUHs8Yo9TUVFWsWDHffSpWrKg6deoUKWA2a9ZMO3fu1IcffqgHHnigVGotS127dlXVqlUlSY899pgefPBBrVy5Ut98841at25d4LH33ntvnoE0JiZGnTp1yrNTLP39s4+JiVHPnj116NAhLV26tEwC6cV/IKJ4kpOTFRgYaHUZQLljyh4up02bNpKkAwcOOLZduHBBU6ZM0XXXXafo6Ohcx3Tu3Fl9+/bVmjVr9M033ziOiY6OVqNGjfT666/nGX569+6tli1b5lvLt99+q88++0wDBgzIs6Pn7++v119/3XG7Xbt2ateuXa79Lj0fL3s6+vXXX9f06dPVsGFD+fv7a8eOHapQoYLGjx+f6z727t0rLy8vvfPOO45tZ86c0dNPP606derI399f11xzjV599VVlZWXl+5ykv6fHFyxYoOTkZMcUc/a5ZxkZGZo4caKjpnr16mnUqFFKS0vLcR/16tXTfffdp7Vr16pFixaqWLGi5syZU+Djent7a8yYMfrxxx/14YcfFrhvtu7du+u6667ThAkT8pzqL4wdO3bonnvuUXBwsIKCgnTXXXc5XifZsqfSv/76a0VFRSk0NFSBgYH697//rRMnThTrcSXpzjvvlCQdOnTosvv27NlTO3fu1J49exzbEhIStGHDBvXs2TPf477++msdPnxY3bt3V/fu3fXll1/qjz/+KHSNH330kZo0aaKAgAA1adIk37G59BzS3377TUOGDNH111+vihUr6sorr9RDDz2kw4cP53l8SkqKBg8erCuvvFLBwcHq06ePTp8+nWu///73v2rTpo0CAwNVqVIlderUST///LPj+/369dOMGTMcNWV/ZcvKytL06dN14403KiAgQNWrV9fgwYNzPdb333+viIgIVa1aVRUrVlT9+vX1yCOPXPbnlf3aX7dunZo1a6aAgAA1btw4Vyc7+zX1v//9T0OGDFG1atV01VVXOb4/c+ZM3XjjjfL391etWrU0dOjQfE+32LZtm2677TZHnbNnz75snZK0Z88ede3aVVdccYUCAgLUokULrVq1Ks86N23apCeffFKhoaEKCQnR4MGDlZ6erjNnzqhPnz6qUqWKqlSpouHDhxf7vQjPRSCFy8n+ZValShXHtk2bNun06dPq2bNnvh3NPn36SJI+/fRTxzGnTp1Sz5495ePjU6xasv/h7t27d7GOv5wFCxbo7bff1qBBgzR16lTVrFlTbdu21fLly3PtGxcXJx8fHz300EOS/v7l3rZtWy1ZskR9+vTRW2+9pbCwMI0cOVJRUVEFPu7ixYvVpk0b+fv7a/HixY7zcqW/u9Rjx47VLbfcojfeeENt27ZVdHS0unfvnut+9u7dqx49eqhDhw568803C3VhVM+ePXXttdcWOmD6+PhozJgx+uGHHwodYi/2888/q02bNvrhhx80fPhwvfjiizp06JDatWunb7/9Ntf+TzzxhH744QeNGzdOjz/+uD755JN8z9ssjOw/rK688srL7nv77bfrqquuUkxMjGNbXFycgoKC1KlTp3yPW7p0qRo2bKhbb71VnTt3ls1m07JlywpV37p16/Tggw/Ky8tL0dHR6tKli/r371+oC5C+++47bd68Wd27d9dbb72lxx57TOvXr1e7du2UkpKSa/9hw4Zp9+7deumll9SnTx8tXbpUXbp0yfE6WLx4sTp16qSgoCC9+uqrevHFF/XLL78oPDzc8W/D4MGD1aFDB8f+2V/ZBg8erOeff15hYWF688031b9/fy1dulQRERGy2+2S/p4h6Nixow4fPqwRI0bo7bffVq9evXL9oZKfffv2KTIyUvfcc4+io6NVoUIFPfTQQ4qPj8+175AhQ/TLL79o7NixGjFihKS/zxseOnSoatWqpalTp+rBBx/UnDlz1LFjR0eN2U6fPq17771XzZs312uvvaarrrpKjz/+uObPn19gjT///LP++c9/avfu3RoxYoSmTp2qwMBAdenSJc/30hNPPKF9+/Zp/Pjx+te//qW5c+fqxRdfVOfOnZWZmalXXnlF4eHhmjJlSo6fN1AoBnBSCxYsMJLM559/bk6cOGF+//13s2LFChMaGmr8/f3N77//7th3+vTpRpL58MMP872/U6dOGUnmgQceMMYY8+abb172mMv597//bSSZ06dPF2r/tm3bmrZt2+ba3rdvX1O3bl3H7UOHDhlJJjg42Bw/fjzHvnPmzDGSzK5du3Jsb9y4sbnzzjsdtydOnGgCAwPNr7/+mmO/ESNGGB8fH3PkyJECa+3bt68JDAzMsW3nzp1Gknn00UdzbH/uueeMJLNhwwbHtrp16xpJZs2aNQU+Tl6P9/777xtJZuXKlY7vSzJDhw513M7+GU2ZMsVkZGSYa6+91jRt2tRkZWUZY4wZN26ckWROnDhR4ON26dLF+Pn5mQMHDji2HT161FSqVMncfvvtjm3Zr8f27ds7HsMYY5555hnj4+Njzpw5U+DjZNezd+9ec+LECXPo0CEzZ84c4+/vb6pXr26Sk5NzPM53332X69gTJ06Y5557zlxzzTWO7916662mf//+ef6MjDEmPT3dXHnllWb06NGObT179jRNmzYtsN5szZo1MzVr1szx/NatW2ck5XjNZj/+uHHjHLdTUlJy3d+WLVuMJLNo0SLHtuzn3Lx5c5Oenu7Y/tprrxlJ5uOPPzbGGHPu3DkTEhJiBg4cmOM+ExISTOXKlXNsHzp0qMnrV9xXX31lJJmlS5fm2L5mzZoc2z/88MNc41BY2a/9//znP45tZ8+eNTVr1jQ333xzrucdHh5uMjIyHNuPHz9u/Pz8TMeOHU1mZqZj+zvvvGMkmfnz5zu2tW3b1kgyU6dOdWxLS0szzZo1M9WqVXP8PLPfLwsWLHDsd9ddd5mbbrrJpKamOrZlZWWZ2267zVx77bW56oyIiMjx2m/durXx8vIyjz32mGNbRkaGueqqq/L8dw4oCB1SOL327dsrNDRUderUUdeuXRUYGKhVq1blmNo6d+6cJKlSpUr53k/297KvaM7+b0HHXE5p3EdBHnzwQYWGhubY9sADD6hChQqKi4tzbPvpp5/0yy+/KDIy0rHtgw8+UJs2bVSlShWdPHnS8dW+fXtlZmbqyy+/LHI9q1evlqRcHdZnn31WkvTZZ5/l2F6/fn1FREQU+XF69epV7C7pRx99VOjHyczM1Lp169SlSxc1aNDAsb1mzZrq2bOnNm3alOMKeOnvc5Ivnv5t06aNMjMz9dtvvxXqMa+//nqFhoaqfv36Gjx4sK655hp99tlnstlshTq+Z8+e2r9/v7777jvHfwuarv/vf/+rv/76Sz169HBs69Gjh3744Ycc09x5OXbsmHbu3Km+ffuqcuXKju0dOnRQ48aNL1vrxecL2+12/fXXX7rmmmsUEhKi7du359p/0KBB8vX1ddx+/PHHVaFCBcfrLj4+XmfOnFGPHj1yvKZ9fHzUqlUrffHFF5et6YMPPlDlypXVoUOHHPfRvHlzBQUFOe4jJCRE0t8zKpd2JAujVq1a+ve//+24nX0Kwo4dO5SQkJBj34EDB+aYpfn888+Vnp6up59+Wt7e3jn2Cw4OzvU+q1ChggYPHuy47efnp8GDB+v48ePatm1bnvWdOnVKGzZsULdu3XTu3DnHz+Gvv/5SRESE9u3bl2s1kwEDBuR47bdq1UrGGA0YMMCxzcfHRy1atNDBgwcL82MCHAikcHozZsxQfHy8VqxYoXvvvVcnT56Uv79/jn2yA2F2MM3LpaE1ODj4ssdcTmncR0Hq16+fa1vVqlV111135Zi2j4uLU4UKFXJc1LNv3z6tWbNGoaGhOb7at28v6e8pyaL67bff5O3trWuuuSbH9ho1aigkJCRXKMur/sLIDpg7d+4sdMDs1auXrrnmmiKdS3rixAmlpKTo+uuvz/W9G264QVlZWbmWWbr66qtz3M4+dSSvcx3z8p///Efx8fHauHGj9u/fr59++knNmzcv1LGSdPPNN6tRo0aKiYnR0qVLVaNGDcd5qHlZsmSJ6tevL39/f+3fv1/79+9Xw4YNZbPZtHTp0gIfK3s8r7322lzfy+tndqkLFy5o7NixjnOYq1atqtDQUJ05c0Znz57Ntf+ljxMUFKSaNWs6puL37dsn6e/zbi99Xa9bt65Qr+l9+/bp7NmzqlatWq77OH/+vOM+2rZtqwcffFDjx49X1apVdf/992vBggW5zpXOzzXXXJPrvPTrrrtOknKdQ3vp+yT7537pz9jPz08NGjTI9T6rVatWrguh8nusbPv375cxRi+++GKun8O4ceMk5f434tLXfvYfKXXq1Mm1vbDvByAbV9nD6bVs2dJxlX2XLl0UHh6unj17au/evQoKCpL0d3iQpB9//FFdunTJ835+/PFHSXJ0dho1aiTp72WG8jvmci6+j+yLrQri5eWVZ1jKzMzMc//8rkjv3r27+vfvr507d6pZs2Zavny57rrrLsfV29LfF2506NAh1xXZ2bJ/YRVHYZdXKuiK+svp1auXJk6cqAkTJhRqfLJDbL9+/fTxxx8X+3EL8zh5KWwIvv3223OMU3H07NlTs2bNUqVKlRQZGZmji3axpKQkffLJJ0pNTc0zVMbExGjSpElltlzWE088oQULFujpp59W69atVblyZXl5eal79+6XvbAuL9nHLF68WDVq1Mj1/cIsOZWVlaVq1arlG8azZyS8vLy0YsUKffPNN/rkk0+0du1aPfLII5o6daq++eYbx789paEk75Piyv5ZPvfcc/nOYlz6h2d+r/28thf2/QBkI5DCpfj4+Cg6Olp33HGH3nnnHccFAOHh4QoJCVFMTIxGjx6d5z+QixYtkiTdd999jmOqVKmiZcuWadSoUcW6sKlz586Kjo7WkiVLChVIq1SpkudUVmGne7N16dJFgwcPdkzb//rrrxo5cmSOfRo2bKjz5887OqKloW7dusrKytK+ffscfwRIUmJios6cOaO6deuW2mMVJ2A+/PDDevnllx0XXVxOaGiobDab9u7dm+t7e/bskbe3d67ujzPo2bOnxo4dq2PHjhV48cjKlSuVmpqqWbNm5QrBe/fu1ZgxY/T1118rPDw8z+OzxzO7M3np8ZezYsUK9e3bV1OnTnVsS01NzfdK8X379umOO+5w3D5//ryOHTume++9V9Lfr2lJqlat2mVf1/mF7IYNG+rzzz9XWFhYoYLgP//5T/3zn//UpEmTFBMTo169eik2Nvayy2ZldyAvriP7QzIu/YSrS2X/3Pfu3ZvjVJL09HQdOnQo13M/evRoruWiLvdY2ffr6+tbqv9GAMXFlD1cTrt27dSyZUtNnz5dqampkiSbzabnnntOe/fuzXPdz88++0wLFy5URESE/vnPfzqOeeGFF7R792698MILef5Fv2TJEm3dujXfWlq3bq27775b7733Xp5Ty+np6Xruuecctxs2bKg9e/bkWCbohx9+0Ndff13o5y/9fX5bRESEli9frtjYWPn5+eXqInbr1k1btmzR2rVrcx1/5swZZWRkFOkxJTmCwfTp03NsnzZtmiQVeKV3cTz88MO65ppr8lzmKi8XT/VfunRNfvt37NhRH3/8cY6pzcTERMXExCg8PNxxWoYzadiwoaZPn67o6OgClyVbsmSJGjRooMcee0xdu3bN8fXcc88pKCiowGn7mjVrqlmzZnr//fdzTLHHx8frl19+uWydPj4+ud5Xb7/9dr4zAnPnzs1xvuasWbOUkZGhe+65R5IUERGh4OBgvfLKK3me13nx+yo7nF0afrt166bMzExNnDgx1/EZGRmO/U+fPp2r9uxVIgozbX/06NEcV6onJSVp0aJFatasWZ7d3Yu1b99efn5+euutt3LUMG/ePJ09ezbX+ywjIyPHkmrp6emaM2eOQkND8z0dpFq1amrXrp3mzJmjY8eO5fp+SZYyA4qDDilc0vPPP6+HHnpICxcu1GOPPSZJGjFihHbs2KFXX31VW7Zs0YMPPqiKFStq06ZNWrJkiW644Qa9//77ue7n559/1tSpU/XFF1+oa9euqlGjhhISEvTRRx9p69at2rx5c4G1LFq0SB07dtQDDzygzp0766677lJgYKD27dun2NhYHTt2zLEW6SOPPKJp06YpIiJCAwYM0PHjxzV79mzdeOONuS6euZzIyEg9/PDDmjlzpiIiIhwXYVz83FatWqX77rtP/fr1U/PmzZWcnKxdu3ZpxYoVOnz4cJGnjps2baq+fftq7ty5OnPmjNq2bautW7fq/fffV5cuXXJ0t0qDj4+PRo8erf79+xf6mOyp/p07dxZq/5dfflnx8fEKDw/XkCFDVKFCBc2ZM0dpaWl67bXXill52XvqqacK/P7Ro0f1xRdf6Mknn8zz+/7+/oqIiNAHH3ygt956K8fFRBeLjo5Wp06dFB4erkceeUSnTp3S22+/rRtvvFHnz58vsIb77rtPixcvVuXKldW4cWNt2bJFn3/+eb5LXKWnp+uuu+5St27dtHfvXs2cOVPh4eGObndwcLBmzZql3r1765ZbblH37t0VGhqqI0eO6LPPPlNYWJhjHd7sIPbkk08qIiJCPj4+6t69u9q2bavBgwcrOjpaO3fuVMeOHeXr66t9+/bpgw8+0JtvvqmuXbvq/fff18yZM/Xvf/9bDRs21Llz5/Tuu+8qODjY8YdZQa677joNGDBA3333napXr6758+crMTFRCxYsuOyxoaGhGjlypMaPH6+7775b//rXvxw/j1tvvVUPP/xwjv1r1aqlV199VYcPH9Z1112nuLg47dy5U3Pnzs13XKW/z88PDw/XTTfdpIEDB6pBgwZKTEzUli1b9Mcff+iHH364bK1AqbHm4n7g8vJa/iZbZmamadiwoWnYsGGO5VIyMzPNggULTFhYmAkODjYBAQHmxhtvNOPHjzfnz5/P97FWrFhhOnbsaK644gpToUIFU7NmTRMZGWk2btxYqFpTUlLM66+/bm699VYTFBRk/Pz8zLXXXmueeOIJs3///hz7LlmyxDRo0MD4+fmZZs2ambVr1+a77NOUKVPyfcykpCRTsWJFI8ksWbIkz33OnTtnRo4caa655hrj5+dnqlatam677Tbz+uuv51heJy95LftkjDF2u92MHz/e1K9f3/j6+po6deqYkSNH5lg6xpi/l77p1KlTgY9R2Mdr2LBhgcs+XSr7taNCLPtkjDHbt283ERERJigoyNhsNnPHHXeYzZs353mfl74ev/jiCyPJfPHFFwU+RmGXobrcsk8FufhnNHXqVCPJrF+/Pt/9Fy5cmGNZpfz85z//MTfccIPx9/c3jRs3NitXrsz1ms1+/IuXfTp9+rTp37+/qVq1qgkKCjIRERFmz549pm7duqZv3765nvP//vc/M2jQIFOlShUTFBRkevXqZf76669c9XzxxRcmIiLCVK5c2QQEBJiGDRuafv36me+//96xT0ZGhnniiSdMaGio8fLyyrUE1Ny5c03z5s1NxYoVTaVKlcxNN91khg8fbo4ePWqM+fs10aNHD3P11Vcbf39/U61aNXPffffleIz8ZL/2165da/7xj38Yf39/06hRI/PBBx/k2K+gf+OM+XuZp0aNGhlfX19TvXp18/jjj+daYq5t27bmxhtvNN9//71p3bq1CQgIMHXr1jXvvPNOjv3yWvbJGGMOHDhg+vTpY2rUqGF8fX1N7dq1zX333WdWrFhx2Trze13m914GCuJlDGceAwBQWurVq6cmTZo4PoQDwOVxDikAAAAsRSAFAACApQikAAAAsBTnkAIAAMBSdEgBAABgKQIpAAAALOUSC+NnZWXp6NGjqlSpUpl95jIAAACKzxijc+fOqVatWvL2LlrP0yUC6dGjR53y86QBAACQ0++//66rrrqqSMe4RCCtVKmSpL+f4MWfK22327Vu3TrHR7/B/TDGnoFx9gyMs/tjjD1DfuOclJSkOnXqOHJbURQ5kH755ZeaMmWKtm3bpmPHjunDDz9Uly5dCjxm48aNioqK0s8//6w6depozJgx6tevX6EfM3uaPjg4OFcgtdlsCg4O5oXvphhjz8A4ewbG2f0xxp7hcuNcnNMri3xRU3Jyspo2baoZM2YUav9Dhw6pU6dOuuOOO7Rz5049/fTTevTRR7V27doiFwsAAAD3U+QO6T333KN77rmn0PvPnj1b9evX19SpUyVJN9xwgzZt2qQ33nhDERERRX14AAAAp2eMUUpKitVllAm73a7U1FSV5lL2ZX4O6ZYtW9S+ffsc2yIiIvT000/ne0xaWprS0tIct5OSkiT9/QOw2+2O7dn/f/E2uBfG2DMwzp6BcXZ/jPHfjDFq166dtmzZYnUpZer48eMKCQlx3C7JuJd5IE1ISFD16tVzbKtevbqSkpJ04cIFVaxYMdcx0dHRGj9+fK7t69atk81my7U9Pj6+9AqGU2KMPQPj7BkYZ/fn6WOcmprq9mFUkjZs2KCAgADH7ZJ0hJ3yKvuRI0cqKirKcTv7qq2OHTvmuqgpPj5eHTp04ORpN8UYewbG2TMwzu6PMf5bcnKy4///+OMPBQYGWlhN6dm/f7+ioqI0Y8YM/fLLL7rvvvvk5+fn+H72jHZxlHkgrVGjhhITE3NsS0xMVHBwcJ7dUUny9/eXv79/ru2+vr55vsDz2w73wRh7BsbZMzDO7s/Tx/ji5x4SEuIWgdQYo6NHjyouLk5Vq1bVwYMH5efnl+O5lmTMy/yjQ1u3bq3169fn2BYfH6/WrVuX9UMDAACghPbs2aNevXrpX//6l2rWrFkmj1HkQHr+/Hnt3LlTO3fulPT3sk47d+7UkSNHJP093d6nTx/H/o899pgOHjyo4cOHa8+ePZo5c6aWL1+uZ555pnSeAQAAAMrEsWPHNHToUE2bNq1MH6fIgfT777/XzTffrJtvvlmSFBUVpZtvvlljx46V9Hfh2eFUkurXr6/PPvtM8fHxatq0qaZOnar33nuPJZ8AAACc2N69e+Xv76+VK1eqRo0aZfpYRT6HtF27dgWuO7Vw4cI8j9mxY0dRHwoAAAAW+Pnnn/XUU08pJiZGV1xxRZk/nlNeZQ8AAHAxV1po/uKr7F3V8uXLFRMTo2rVqpXL4xFIAQCAUzPGKDw8XJs3b7a6FLe3a9cuxcfH57kefFkikAIAAKeWkpLikmE0LCwszw/0cVa7du1SVFSUli1bVu6PTSAFAAAuIzEx0WXW9bTZbPLy8rK6jEI5efKkQkJCtGzZMlWtWrXcH59ACgAAXEZgYKDLBFJXsXPnTj3//PP69NNP8/xgovJQ5gvjAwAAwDmlp6dr4sSJiouLsyyMSnRIAQAAPNL27duVnJysFStWWH5qAR1SAAAAD7Nt2zaNGDFCTZo0sTyMSnRIAQAAPEpWVpb++OMPLV++XCEhIVaXI4lACgAAykBpLmTvDgvNO4vvvvtOM2fO1IIFC6wuJQcCKQAAKFUsZO+cDh48qBdffFFxcXFWl5IL55ACAIBSVVYL2bvaQvPOZMeOHbriiiv0n//8R5UrV7a6nFzokAIAgDJTmgvZu9JC885ky5YtmjBhguLi4px2DVcCKQAAKDMsZG+9NWvWKC4uTsHBwVaXki8CKQAAgBvavHmztm/frvHjx1tdymURSAEAANzMli1bNGnSJMXGxlpdSqEQSAEAANxIQkKCatWqpbi4OAUFBVldTqFwlT0AAICb+PLLLzVw4EDVrl3bZcKoRIcUAABLleYC8laz2+1KTU1lIXuLJCcna8aMGYqNjVWFCq4V8VyrWgAA3AgLyKO0bNy4UTabzSkXvS8MpuwBALBIWS0g7yxYyL58fPHFF5o2bZqaNGlidSnFRocUAAAnUJoLyFvFbrdr7dq1ioiIkK+vLwvZl4OMjAydO3dOsbGxLh3+CaQAADgBd1hA3m63KyAgQIGBgfL19bW6HLf3+eefa+XKlZo5c6bVpZQYgRQAAMDF/PTTT3rnnXe0bNkyq0spFZxDCgAA4EI2b96sq6++WrGxsapYsaLV5ZQKAikAAICLWLt2rV5//XX5+fkpICDA6nJKDVP2AAC35szrfLJeJ4rCGKMtW7YoJibGrcKoRCAFALgx1vmEu1i9erWOHj2ql156yepSygSBFADgtlxlnU/W60RB1q5dqwULFmjJkiVWl1JmCKQAAI/gzOt8sl4n8vP777/rhhtu0JIlS+Tv7291OWWGQAoA8AjusM4nPMuqVasUExOjZcuWuf0fLFxlDwAA4GROnTqllStXatGiRW4fRiU6pAAAAE7lo48+Uv369bVw4UKrSyk3dEgBAACcxMqVKxUXF6fGjRtbXUq5IpACAAA4gfT0dPn5+WnRokXy9fW1upxyxZQ9AKDECrP4vN1uV2pqqpKTk8vtly0Lz8NVrFixQt9++62mTJlidSmWIJACAEqExeeBkvnmm2/00UcfedQ5o5diyh4AUCKusPg8C8/DWX3++ee68cYbtXDhQlWo4Ll9Qs995gCAUlfQ4vN2u11r165VREREuZ8fx8LzcEbLli3Tf//7X7Vr186jw6hEIAUAlKKCFp+32+0KCAhQYGCgx12wAVwqMzNThw4d0vz58z0+jEoEUgAAgHK1dOlSeXl5adSoUVaX4jQ4hxQAAKCcxMXFaf369YqMjLS6FKdChxQAAKAcHDx4UGFhYeratat8fHysLsep0CEFAAAoYwsXLtTkyZN11VVXEUbzQIcUAMpAYRaKdxcsPg8U7NixY/ruu+80e/Zsq0txWgRSAChlLBQPINv777+v1q1ba8aMGVaX4tSYsgeAUuYKC8WXBRafB3J67733tGXLFl1zzTVWl+L06JACQBkqaKF4d8Pi88D/l5qaqquuukqPPPKIvL3p/10OgRQAylBBC8UDcE9z5sxRYmKixo4da3UpLoNACgAAUEri4+O1a9cuvf3221aX4lIIpAAAAKXg448/VocOHdS+fXtOXykiTmoAAAAooRkzZmjDhg2qWLEiYbQYCKQAAAAlkJ6ertTUVE2fPp0wWkxM2QNAERRmwXsWigc8x5tvvql69erp2WeftboUl0YgBYBCYsF7ABebM2eOjhw5oieffNLqUlwegRQACqmoC96zUDzgvvbs2aPOnTurZs2aTNOXAgIpABRDYRa8Z6F4wD1NnTpVJ06c0OTJk60uxW0QSAGgGFjwHvBMBw4c0KlTpxQdHW11KW6Fq+wBAAAKYfr06fLz89OkSZOY/ShldEgBAAAuY/LkyTp37pyuuuoqq0txSwRSAACAAiQnJ6tVq1Zq164dndEyQiAFAADIx8svv6zg4GCWdipjnEMKAACQhxUrVshut+uJJ56wuhS3R4cUAADgEsuWLdODDz6orl27Wl2KRyCQAgAAXOSll16St7e3/Pz8rC7FYxBIAQAA9PfHA6ekpKhmzZoaPHiw1eV4FM4hBQAAHs8Yo7Fjx2rr1q2EUQsQSAEAgMebPHmybDab7rjjDqtL8UhM2QMAAI9ljNGuXbv06KOPKjQ01OpyPBYdUgAA4JGMMRo5cqTWrl1LGLUYHVIA5Sb7goFL2e12paamKjk5Wb6+vhZUVjjJyclWlwCgFO3atUuhoaF69tlnrS7F4xFIAZQLY4zCw8O1efNmq0sB4OGMMZowYYKGDBlCGHUSTNkDKBcpKSluE0bDwsJks9msLgNAMRhj9Pzzzys4OJhpeidChxRAuUtMTFRgYKDjtt1u19q1axUREeHUU/bZbDabvLy8rC4DQBEZY3Tu3Dk98MADuu2226wuBxchkAIod4GBgbkCaUBAgAIDA10ikAJwPcYYRUVF6ZZbblHv3r2tLgeXYMoeAAC4vQULFqhBgwaEUSdFhxQAALgtY4zmz5+vfv36ycfHx+pykA86pAAAwC0ZY/Tkk08qPT2dMOrk6JACAAC3Y4zR2bNn1bp1a/Xs2dPqcnAZBFIA+cpvIfviYFF5AOUlKytLw4YN0yOPPEIYdREEUgB5YiF7AK5qxIgRuvnmm9WiRQurS0EhEUgB5KmsFrJnUXkAZSUrK0vbt2/XiBEjdMUVV1hdDoqAQArgsi5dyL4kWFQeQFnIysrSY489ptatW9MZdUEEUgCXdelC9gDgbL799lu1bt1a/fv3t7oUFAPLPgEAAJeVmZmp5557TjfeeCNh1IURSAEAgEvKysrSoEGD1LRpUwUHB1tdDkqAKXsAAOByMjMzde7cOQ0ZMkTNmze3uhyUEB1SAADgUjIzMzVgwAB99dVXhFE3QYcUcEKluSB9cbGQPQBn9c4776hjx47q3Lmz1aWglBBIASfDgvQAkLeMjAy9++67evLJJ1k+zs0wZQ84mbJakL64WMgegDPIyMhQ//79dcUVVxBG3RAdUsCJleaC9MXFQvYArJaVlaXTp0+rW7duTNO7KQIp4MRYkB6Ap7Pb7erXr59efPFFwqgbY8oeAAA4rSeeeEIPPPCAGjVqZHUpKEN0SAEAgNOx2+3avn27XnvtNRa99wB0SAEAgFNJT0/Xww8/rGPHjhFGPQQdUsBil645yvqfADzdV199pZ49e+r++++3uhSUEwIpYCHWHAWA/y89PV3PPPOMpk6dqoCAAKvLQTliyh6wUEFrjrL+JwBPYrfb9fDDD+uee+4hjHogOqSAk7h0zVHW/wTgKdLS0pSSkqKxY8eqSZMmVpcDC9AhBZxE9pqj2V+EUQCeIDU1VT179tQPP/xAGPVgBFIAAGCZN954Q48++qjatWtndSmwEFP2AACg3KWmpmrevHkaMWIEM0KgQwoAAMpXamqqevTooWuvvZYwCkl0SAEAQDnKzMzUqVOn9OSTT+qOO+6wuhw4CTqkQBkxxig5OfmyXwDgKVJSUvTAAw8oIyODMIoc6JACZYAF7wEgt0GDBumpp57S1VdfbXUpcDIEUqAMFLTgfV5YBB+AO0tJSdHOnTs1Z86cHOstA9kIpEAZu3TB+7ywCD4Ad5WcnKzu3bvrueeeI4wiXwRSoIxlL3QPAJ7oiy++0HPPPae2bdtaXQqcWLEuapoxY4bq1aungIAAtWrVSlu3bi1w/+nTp+v6669XxYoVVadOHT3zzDNKTU0tVsEAAMD5nT9/XgMHDtTdd99NGMVlFTmQxsXFKSoqSuPGjdP27dvVtGlTRURE6Pjx43nuHxMToxEjRmjcuHHavXu35s2bp7i4OI0aNarExQMAAOdz4cIFde/eXX379lWFCkzG4vKKHEinTZumgQMHqn///mrcuLFmz54tm82m+fPn57n/5s2bFRYWpp49e6pevXrq2LGjevTocdmuKgAAcD0XLlxQWlqapk2bpvDwcKvLgYso0p8t6enp2rZtm0aOHOnY5u3trfbt22vLli15HnPbbbdpyZIl2rp1q1q2bKmDBw9q9erV6t27d76Pk5aWprS0NMftpKQkSZLdbpfdbndsz/7/i7fBvbjqGF/6OnW1+subq44zioZxdn+nTp3SlClTVKdOHbVs2ZKxdlP5vZdLMt5FCqQnT55UZmamqlevnmN79erVtWfPnjyP6dmzp06ePKnw8HAZY5SRkaHHHnuswCn76OhojR8/Ptf2devW5bk0Tnx8fFGeBlyQVWNsjMnxx1FhXXyO9Nq1axUQEFCaZbkt3suegXF2X8uWLVO3bt108uRJrV692upyUMYufS+npKQU+77K/MSOjRs36pVXXtHMmTPVqlUr7d+/X0899ZQmTpyoF198Mc9jRo4cqaioKMftpKQk1alTRx07dlRwcLBju91uV3x8vDp06CBfX9+yfiqwgJVjbIxRu3bt8u3+F1ZERARX2V8G72XPwDi7r7Nnz2rJkiWaP38+Y+wB8nsvZ89oF0eRAmnVqlXl4+OjxMTEHNsTExNVo0aNPI958cUX1bt3bz366KOSpJtuuknJyckaNGiQRo8eLW/v3Kex+vv7y9/fP9d2X1/fPF/g+W2H+7BijJOTk0scRsPCwlS5cmXWGC0k3suegXF2L2fPntXDDz+sCRMmOMaVMfYMl45zSca8SIHUz89PzZs31/r169WlSxdJUlZWltavX69hw4bleUxKSkqu0Onj4yPp7w4U4AoKs7h9XljwHoA7s9vtOnPmjF5++WW1aNGCc0ZRbEWeso+KilLfvn3VokULtWzZUtOnT1dycrL69+8vSerTp49q166t6OhoSVLnzp01bdo03XzzzY4p+xdffFGdO3d2BFPA2bG4PQDkdObMGUVGRmrJkiVq0aKF1eXAxRU5kEZGRurEiRMaO3asEhIS1KxZM61Zs8ZxodORI0dydETHjBkjLy8vjRkzRn/++adCQ0PVuXNnTZo0qfSeBQAAKDfGGD3yyCOaNGmSQkNDrS4HbqBYFzUNGzYs3yn6jRs35nyAChU0btw4jRs3rjgPBQAAnMjp06e1e/duxcTEsIIISk2xPjoUAAB4nlOnTikyMlIBAQGEUZQqPs8LAAAUysaNG/Xqq6/q5ptvtroUuBkCKQAAKNBff/2l559/XvPmzWPlEJQJpuwBAEC+zp49q+7du+vpp58mjKLM0CEFAAB5OnnypHx9ffXee++pbt26VpcDN0aHFAAA5HLixAl1795dx44dI4yizBFIAQBALm+88YamT5+uRo0aWV0KPABT9gAAwOH48eNavny5XnnlFatLgQehQwoAACRJiYmJ6tGjh+68806rS4GHoUMKAACUlpam8+fP65133tENN9xgdTnwMHRIgf9jjFFycnKOLwDwBMeOHVOnTp0UGhpKGIUl6JAC+juMhoeHa/PmzVaXAgDlKisrSwMHDtSMGTMUHBxsdTnwUARSQFJKSkq+YTQsLEw2m62cKwKAsnf06FH99ttvWrlypfz8/KwuBx6MKXvgEomJiTp//rzj66uvvuLTSQC4nT///FMPP/ywqlatShiF5eiQApcIDAxUYGCg1WUAQJnatGmT5syZo2uvvdbqUgA6pAAAeJI//vhDAwYMULdu3QijcBp0SAEA8BDHjx9Xnz599O6773IqEpwKgRQAAA/wxx9/KDg4WEuXLlXNmjWtLgfIgSl7AADc3G+//aY+ffrozJkzhFE4JTqkcFnGGKWkpJTKfbEIPgB39s4772j+/Pm6+uqrrS4FyBOBFC6JhewB4PIOHz6s1atXa8qUKVaXAhSIKXu4pIIWsi8JFsEH4C4OHTqkRx55RPfdd5/VpQCXRYcULi8xMbHU1g212WxceQrA5aWkpCg9PV0LFy5kmh4ugUAKl8dC9gDw/x04cECDBw/Wp59+qoCAAKvLAQqFKXsAANyE3W7XE088oYULFxJG4VLokAIA4Ab27dun06dPa9WqVapQgV/vcC10SAEAcHH79u3T4MGDVbt2bcIoXBKvWgAAXJgxRt99952WLFmiWrVqWV0OUCwEUgAAXNTevXs1depUzZ071+pSgBIhkAIA4IKOHDmiIUOGaOnSpVaXApQY55ACAOBiDhw4oCpVqmj58uWqUaOG1eUAJUYgBQDAhfzyyy8aNGiQUlNTdeWVV1pdDlAqCKQAALiQefPmadmyZQoNDbW6FKDUcA4pAAAu4KefftKWLVs0depUq0sBSh0dUgAAnNyuXbv09NNPq0uXLlaXApQJOqQAADixc+fOqUKFCoqNjVXVqlWtLgcoE3RIAQBwUj/88IO6du2qa6+9ljAKt0aHFC7BGKPk5GTH7Yv/HwDcUUpKikaNGqWYmBg+DhRuj1c4nJ4xRu3atdOWLVusLgUAysWOHTskSZ988om8vZnMhPvjVQ6nl5aWlm8YDQsLk81mK+eKAKDsbN++XS+88ILq1q1LGIXHoEMKl5KYmKjAwEDHbZvNJi8vLwsrAoDSY4zRL7/8ori4OFWpUsXqcoByQyCFSwkMDMwRSAHAXXz//fdasGCBZsyYYXUpQLkjkAIAYLE9e/Zo9OjRiouLs7oUwBKcnAIAgIV+/vln1a5dWx988IFCQkKsLgewBIEUAACLfPvtt3ruuedkjFFwcLDV5QCWIZACAGABY4zi4uIUFxdHGIXH4xxSAADK2ZYtW7R3715NmzbN6lIAp0CHFACAcrR582ZNnDhRDz74oNWlAE6DQAoAQDk5ffq0QkJCFBcXp0qVKlldDuA0CKQAAJSDr776Sv369VOjRo0Io8AlCKQAAJSxM2fOaNq0aVq6dCkfBwrkgYuaAAAoQ//73/9UtWpVrVy5ko86BvLBn2kAAJSRjRs36vXXX1e9evUIo0AB6JACAFAGsrKy9OeffyouLk42m83qcgCnRiAFAKCUrV+/XqtXr9bUqVOtLgVwCQRSAABK0bZt2/TWW28pNjbW6lIAl8E5pAAAlJLvv/9e119/vWJjY1WxYkWrywFcBoEUAIBSsHbtWk2aNEkVKlQgjAJFRCAFAKCEsrKy9Pnnn2vZsmUKCAiwuhzA5XAOKQAAJbBmzRqdOXNGU6ZMsboUwGXRIQUAoJj++9//6r333tO///1vq0sBXBqBFACAYjhx4oTq1aunpUuXyt/f3+pyAJdGIAUAoIg++eQTPfXUU2rUqBFhFCgFnEOKMmOMUUpKSonuw263KzU1tZQqAoCSS0hI0LJly7Rw4UI+DhQoJQRSlAljjMLDw7V582arSwGAUvPpp5+qUaNGWrp0KWEUKEVM2aNMpKSklHoYDQsL4/OgAVjmww8/1JIlS1S3bl3CKFDK6JCizCUmJiowMLBYx9rtdq1du1YRERGqXLkyvwQAWCIzM1OpqalavHixfH19rS4HcDsEUpS5wMDAEgXSgIAABQYGEkYBWOI///mPdu7cqYkTJ1pdCuC2CKQAAOTjf//7n1auXKmFCxdaXQrg1gikAADkYdOmTWrevLnef/99VajAr0ugLHFREwAAl4iLi9PcuXMVEBBAGAXKAYEUAICL2O12/fjjj5o/fz5hFCgnvNMAAPg/MTExCgoK0qRJk6wuBfAodEgBAJC0bNkyxcfHq1OnTlaXAngcOqQAAI939OhR3XLLLerWrZt8fHysLgfwOARSAIBHW7RokTZv3qzZs2dbXQrgsQikAACPdejQIX399deaOXOm1aUAHo1zSAEAHmnp0qWqUKGC5syZwzQ9YDECKQDA48yfP19fffWVateubXUpAEQgBQB4mIyMDAUHB2vmzJny9ubXIOAMOIcUAOAx5s6dqzNnzmj48OFWlwLgIgRSAIBH+OSTT/TDDz/o7bfftroUAJcgkAIA3F58fLzuvPNOderUiWl6wAnxrgQAuLWZM2dq1apVstlshFHASfHOBAC4rZSUFJ0+fVpvvfWWvLy8rC4HQD6YsgcAuKV33nlHN9xwg0aPHm11KQAugw4pAMDtzJw5UwcPHtSdd95pdSkACoEOKQDArRw5ckQRERF6/PHHmaYHXAQdUgCA23jjjTc0e/ZsNWzYkDAKuBA6pCgVxhilpKQ4bicnJ1tYDQBP9NNPPykxMVHR0dFWlwKgiOiQosSMMQoPD1dQUJDjq3r16laXBcCDzJo1S9WqVdPkyZPpjAIuiA4pSiwlJUWbN2/O83thYWGy2WzlXBEAT/Laa6/p9OnTCg0NtboUAMVEIEWpSkxMVGBgoOO2zWajWwGgzKSlpalRo0bq3Lkz/9YALoxAilIVGBiYI5ACQFl55ZVXdOWVV2rw4MFWlwKghDiHFADgchYvXqzU1FQNGjTI6lIAlAI6pAAAl7Jq1So99NBD8vf3Z5oecBN0SAEALmPChAnasWOHAgICCKOAG6FDCgBwCWfOnFHlypX11FNPWV0KgFJGhxQA4NSMMXrppZf066+/EkYBN0UgBQA4tUmTJsnX11ctW7a0uhQAZYQpewCAUzLG6MCBA+rTp4+uvvpqq8sBUIbokAIAnI4xRqNHj9bHH39MGAU8AIEUAOB0vv32W4WEhOjZZ5+1uhQA5YBACgBwGsYYTZ48WTfccIOGDx9udTkAygmBFADgFIwxeuGFF+Tn56fKlStbXQ6AcsRFTQAAyxljdOHCBbVv314dO3a0uhwA5YxACgCwlDFGzz77rFq1aqXIyEirywFgAQIpiswYo5SUFMft5ORkC6sB4OpmzJihevXqEUYBD0YgRZEYYxQeHq7NmzdbXQoAF2eM0QcffKDHHntMFSrw6wjwZMW6qCn7r9mAgAC1atVKW7duLXD/M2fOaOjQoapZs6b8/f113XXXafXq1cUqGNZKSUnJN4yGhYXJZrOVc0UAXJExRk899ZROnDhBGAVQ9A5pXFycoqKiNHv2bLVq1UrTp09XRESE9u7dq2rVquXaPz09XR06dFC1atW0YsUK1a5dW7/99ptCQkJKo35YKDExUYGBgY7bNptNXl5eFlYEwFUcP35cN998s/r37291KQCcQJE7pNOmTdPAgQPVv39/NW7cWLNnz5bNZtP8+fPz3H/+/Pk6deqUPvroI4WFhalevXpq27atmjZtWuLiYa3AwMAcX4RRAJeTlZWlp59+Wn/99RdhFIBDkQJpenq6tm3bpvbt2///O/D2Vvv27bVly5Y8j1m1apVat26toUOHqnr16mrSpIleeeUVZWZmlqxyAIDLWbhwoZo0aaLGjRtbXQoAJ1KkKfuTJ08qMzNT1atXz7G9evXq2rNnT57HHDx4UBs2bFCvXr20evVq7d+/X0OGDJHdbte4cePyPCYtLU1paWmO20lJSZIku90uu93u2J79/xdvQ9m69Odf1j97xtgzMM7uLysrS7/88ou6dOmiyMhIxtpN8V72DPmNc0nGvczPJM/KylK1atU0d+5c+fj4qHnz5vrzzz81ZcqUfANpdHS0xo8fn2v7unXr8rxoJj4+vtTrRt5SU1Md/7927VoFBASUy+Myxp6BcXZPWVlZmjNnjq677jrdddddjLMHYIw9w6XjfPGSkEVVpEBatWpV+fj4KDExMcf2xMRE1ahRI89jatasKV9fX/n4+Di23XDDDUpISFB6err8/PxyHTNy5EhFRUU5biclJalOnTrq2LGjgoODHdvtdrvi4+PVoUMH+fr6FuWpoJguXnM0IiIix0VNZYEx9gyMs3tbv369HnzwQfXq1YtxdnO8lz1DfuOcPaNdHEUKpH5+fmrevLnWr1+vLl26SPr7L9/169dr2LBheR4TFhammJgYZWVlydv771NWf/31V9WsWTPPMCpJ/v7+8vf3z7Xd19c3zxd4fttR+i7+OZfnz50x9gyMs3vJysrSuHHjNGrUKFWsWNExncc4uz/G2DNcOs4lGfMiX2UfFRWld999V++//752796txx9/XMnJyY6rJfv06aORI0c69n/88cd16tQpPfXUU/r111/12Wef6ZVXXtHQoUOLXTQAwLllZmZq0KBBuuaaa1SxYkWrywHg5Ip8DmlkZKROnDihsWPHKiEhQc2aNdOaNWscFzodOXLE0QmVpDp16mjt2rV65pln9I9//EO1a9fWU089pRdeeKH0ngUAwGlkZmbqwoUL6tu3r9q0aWN1OQBcQLEuaho2bFi+U/QbN27Mta1169b65ptvivNQAAAXkpmZqUcffVSRkZG6++67rS4HgIso1keHAgCQl9dee03t27cnjAIoEj5AGABQYhkZGYqLi9Pw4cNzrKoCAIVBhxQAUCIZGRl65JFH5OPjQxgFUCx0SAEAxWaM0bFjx3T//ffrwQcftLocAC6KDikAoFgyMjLUt29fZWVlEUYBlAiBFABQLIMHD9a//vUv1a1b1+pSALg4puwBAEVit9v166+/avLkyQoNDbW6HABugA4pAKDQ7Ha7+vTpo3379hFGAZQaAikAoNBWr16tyMhIdenSxepSALgRpuwBAJeVnp6uUaNGafLkyapQgV8dAEoXHVIAQIHS09P18MMPq23btoRRAGWCf1kAAPlKS0tTenq6nn/+ed16661WlwPATdEhBQDkKS0tTb169dKPP/5IGAVQpuiQuhljjFJSUsrs/pOTk8vsvgE4l4kTJ+qRRx5RWFiY1aUAcHMEUjdijFF4eLg2b95sdSkAXFhqaqri4uI0ceJEeXl5WV0OAA/AlL0bSUlJKbcwGhYWJpvNVi6PBaD8pKamqkePHqpRowZhFEC5oUPqphITExUYGFhm92+z2fhlBbgZY4z++OMPDRkyRB06dLC6HAAehEDqpgIDA8s0kAJwLxcuXNDDDz+sWbNmEUYBlDum7AHAwxlj1LdvXw0ZMkTVqlWzuhwAHogOKQB4sJSUFB04cEBz585VSEiI1eUA8FB0SAHAQyUnJysyMlInT54kjAKwFB1SAPBQn3zyiZ599lm1a9fO6lIAeDgCqYsozIL3LFoPoDCSk5M1evRoTZs2Td7eTJQBsB6B1AWw4D2A0pI9Tf/CCy8QRgE4DQKpCyjqgvcsWg8gL+fPn5ckRUdH66abbrK4GgD4/wikLqYwC96zaD2AS507d06RkZGKjo5W06ZNrS4HAHIgkLoYFrwHUBzjx4/XmDFjCKMAnBKBFADcWFJSklauXKkpU6YwcwLAaXFGOwC4qbNnz6pbt25q1KgRYRSAU6NDCgBuKCsrS3/++afGjx+vVq1aWV0OABSIDqkTMsYoOTk5xxcAFNaZM2fUuXNn1a5dmzAKwCXQIXUyrDkKoCSysrL08MMP66WXXlLlypWtLgcACoVA6mQKWnOU9UUBFOT06dP6/ffftWzZMlWqVMnqcgCg0Jiyd2KJiYk6f/684+urr77iwgQAeTp9+rQiIyOVkZFBGAXgcuiQOjHWHAVQWKtWrdLkyZN1yy23WF0KABQZgRQAXNipU6f00ksv6c0332QGBYDLYsoeAFzU6dOn1b17dw0YMIAwCsCl0SEFABd06tQp+fr6asaMGbr22mutLgcASoQOKQC4mJMnT6pbt25KSEggjAJwC3RILWaMUUpKiuM2i+ADuJzx48frjTfeIIwCcBsEUguxCD6Aojh+/LhWr16tt956i3NGAbgVpuwtxCL4AArr+PHj6tGjh1q2bEkYBeB26JA6icTExBxrjtpsNn7pAJAkZWRk6NixY3r77bfVuHFjq8sBgFJHh9RJZC+Cn/1FGAUgSQkJCerUqZOuu+46wigAt0UgBQAnZbfb1bdvX7355puqWLGi1eUAQJlhyh4AnNCxY8f0119/6cMPP+R8cgBujw4pADiZo0ePqlevXvLz8yOMAvAIdEgBwMmsXr1ac+bMYZ1RAB6DQAoATuLPP//Ua6+9pjfffNPqUgCgXBFIAcAJHDt2TL1799bcuXOtLgUAyh2BFAAslpCQoKCgIC1cuFBXX3211eUAQLnjoiYAsNCRI0fUo0cPJSUlEUYBeCwCKQBYKDo6WvPnz1ft2rWtLgUALMOUPQBY4LffftOXX36pWbNmWV0KAFiODikAlLPDhw+rf//+uv32260uBQCcAoEUAMpRenq6/vrrLy1YsEB169a1uhwAcAoEUgAoJwcPHtS//vUv/eMf/yCMAsBFOIe0jBhjlJKSUuA+ycnJ5VQNAKtduHBBgwcP1vz58+Xr62t1OQDgVAikZcAYo/DwcG3evNnqUgA4gf3798tut+vTTz+Vv7+/1eUAgNNhyr4MpKSkFCmMhoWFyWazlWFFAKyyf/9+DR48WMHBwYRRAMgHHdIylpiYqMDAwAL3sdls8vLyKqeKAJSn9evXa9GiRawzCgAFIJCWscDAwMsGUgDu59dff9WcOXM0depUq0sBAKdHIAWAUnbw4EE9/vjjWrJkidWlAIBLIJACQCk6cuSIQkNDFRMTo+rVq1tdDgC4BC5qAoBSsnv3bvXv31/p6emEUQAoAjqkpeDSNUdZXxTwPMYYvfHGG4qJidGVV15pdTkA4FIIpCXEmqMAfv75Z/3444+aO3eu1aUAgEtiyr6EClpzlPVFAff3008/6amnnlL79u2tLgUAXBYd0lJ06ZqjrC8KuLfU1FSlpKRo2bJlCg0NtbocAHBZdEhLUfaao9lfhFHAff3444/q2rWrWrRoQRgFgBKiQwoARXT27Fk9//zziomJkbc3f9cDQEkRSAGgCHbu3KnAwEB9+umn8vX1tbocAHAL/GkPAIW0Y8cODR8+XFdeeSVhFABKEYEUAArp22+/VWxsrK644gqrSwEAt8KUPQBcxrZt2/TBBx9o8uTJVpcCAG6JQAoABfjpp580atQoxcXFWV0KALgtpuwBIB/79u3T1Vdfrbi4OIWEhFhdDgC4LQIpAORh69atGjZsmLy8vAijAFDGCKQAcImsrCzNmzdPy5cvV6VKlawuBwDcHueQAsBFvvnmG/3555+aM2eO1aUAgMegQwoA/2fLli2aMGGCOnToYHUpAOBR6JACgKTk5GT5+PgoLi6OaXoAKGd0SAF4vE2bNqlv37669dZbCaMAYAE6pAA82vHjx/Xqq69q2bJl8vLysrocAPBIdEgBeKxNmzYpJSVFH330kYKCgqwuBwA8FoEUgEf63//+p1dffVWhoaHy8fGxuhwA8GgEUgAexxij3bt3KzY2VoGBgVaXAwAej3NIAXiUL774Qhs3btT48eOtLgUA8H8IpAA8xjfffKPp06dr2bJlVpcCALgIU/YAPMJPP/2kG264QcuWLZPNZrO6HADARQikANxefHy8XnzxRfn7+xNGAcAJEUgBuLWMjAx99NFHWrZsmQICAqwuBwCQB84hBeC21q5dK7vdrhkzZlhdCgCgAHRIAbilNWvWaO7cuWrfvr3VpQAALoMOKQC3k5SUpCuvvFIxMTHy9/e3uhwAwGXQIQXgVj799FM98cQTuvXWWwmjAOAi6JACcBu//fabFi1apMWLF1tdCgCgCOiQAnAL//3vf1WhQgXFxsbSGQUAF0MgBeDyPv74Y73//vsKDQ2Vtzf/rAGAq+FfbgAuzRijxMRELVq0SH5+flaXAwAoBs4hBeCyVq5cqV9//VUjRoywuhQAQAkQSAG4pPj4eK1YsULvv/++1aUAAEqIQArA5Wzbtk0tW7ZUu3bt5Ovra3U5AIAS4hxSAC5l+fLleuONNxQYGEgYBQA3QSAF4DIuXLigb775RgsXLlSFCkzwAIC74F90AC4hNjZW1apV07Rp06wuBQBQyuiQAnB6y5Yt05o1a3T77bdbXQoAoAzQIQXg1E6dOqVGjRqpW7du8vHxsbocAEAZIJACcFqLFy/Wt99+q3feecfqUgAAZYhACsAp/fLLL9q4caPmzp1rdSkAgDJWrHNIZ8yYoXr16ikgIECtWrXS1q1bC3VcbGysvLy81KVLl+I8LAAP8cEHHyg0NFTvvfce0/QA4AGKHEjj4uIUFRWlcePGafv27WratKkiIiJ0/PjxAo87fPiwnnvuObVp06bYxQJwfwsWLFB8fLyuvPJKeXl5WV0OAKAcFDmQTps2TQMHDlT//v3VuHFjzZ49WzabTfPnz8/3mMzMTPXq1Uvjx49XgwYNSlQwAPeVlZUlSZo9e7a8vVkEBAA8RZH+xU9PT9e2bdvUvn37/38H3t5q3769tmzZku9xEyZMULVq1TRgwIDiVwrArcXHx2vWrFnq378/YRQAPEyRLmo6efKkMjMzVb169Rzbq1evrj179uR5zKZNmzRv3jzt3Lmz0I+TlpamtLQ0x+2kpCRJkt1ul91ud2zP/v+Lt5W3S+uxshZ35AxjjLK3fPlyHThwQJMnT2as3RjvZ/fHGHuG/Ma5JONeplfZnzt3Tr1799a7776rqlWrFvq46OhojR8/Ptf2devWyWaz5doeHx9fojpLIjU11fH/a9euVUBAgGW1uDMrxxhla8+ePbr66qs1aNAgrV+/3upyUA54P7s/xtgzXDrOKSkpxb4vL2OMKezO6enpstlsWrFiRY4r5fv27aszZ87o448/zrH/zp07dfPNN+e4Sjb7HDFvb2/t3btXDRs2zPU4eXVI69Spo5MnTyo4ONix3W63Kz4+Xh06dJCvr29hn0apSk5OVpUqVSRJp0+fVmBgoCV1uCtnGGOUnblz5+rnn3/WlClT9PnnnzPObo73s/tjjD1DfuOclJSkqlWr6uzZsznyWmEUqUPq5+en5s2ba/369Y5AmpWVpfXr12vYsGG59m/UqJF27dqVY9uYMWN07tw5vfnmm6pTp06ej+Pv7y9/f/9c2319ffN8gee3vTxc/LhW1uHu+Nm6n7Nnz+rYsWOaMWOGMjIyJDHOnoJxdn+MsWe4dJxLMuZFnrKPiopS37591aJFC7Vs2VLTp09XcnKy+vfvL0nq06ePateurejoaAUEBKhJkyY5jg8JCZGkXNsBeI6ZM2eqefPmevnll60uBQDgBIocSCMjI3XixAmNHTtWCQkJatasmdasWeO40OnIkSNcIQsgXzNmzNC+ffv0+OOPW10KAMBJFOuipmHDhuU5RS9JGzduLPDYhQsXFuchAbiB48ePq02bNhoyZAiL3gMAHPgsewDlYvr06Tp58iTT9ACAXAikAMrc1q1b9ccff2jKlClWlwIAcEKc7AmgTM2bN0/XX3+9pkyZwjQ9ACBPdEgBlJkpU6bor7/+UnBwMGEUAJAvAimAMpGRkaFatWrpueeeI4wCAApEIAVQ6iZPnqyaNWuqb9++VpcCAHABBNIiMsbk+KzW5ORkC6sBnM+8efOUnJysPn36WF0KAMBFEEiLwBij8PBwbd682epSAKe0YcMGde/eXTabjWl6AEChEUiLICUlJd8wGhYWJpvNVs4VAc5j4sSJyszM1J133ml1KQAAF0MgLabExEQFBgY6btMRgic7fvy4/P39NXz4cKtLAQC4INYhLabAwMAcX4RReKoJEybo+PHjhFEAQLERSAEU24QJE+Tt7a0mTZpYXQoAwIUxZQ+gyIwxOnbsmLp166ZGjRpZXQ4AwMXRIQVQJMYYvfjii4qNjSWMAgBKBR3Sy7h43VHWHAWk9evXKygoSFFRUVaXAgBwE3RIC5C97mhQUJCCgoJUvXp1q0sCLGOM0fTp0xUWFqYRI0ZYXQ4AwI0QSAuQ37qjrDkKT2OM0YgRI5SRkaGKFStaXQ4AwM0wZV9IF687ypqj8CTGGKWlpal169bq0qWL1eUAANwQgbSQstcbBTyJMUbPP/+8wsPDCaMAgDLDlD2AfE2bNk116tQhjAIAyhQdUgC5GGO0Zs0aDR06VAEBAVaXAwBwc3RIAeRgjNHTTz+tAwcOEEYBAOWCDimAHI4cOaIbb7xRgwYNsroUAICHoEMKQNLfndFnnnlGWVlZhFEAQLkikAKQJD3zzDO6/vrrVb9+fatLAQB4GKbsAQ+XlZWlP/74Q08++aQaNGhgdTkAAA9EhxTwYFlZWRo6dKg2bNhAGAUAWIZACniwVatWqXnz5urXr5/VpQAAPBhT9oAHysrKUnR0tIYPHy5fX1+rywEAeDg6pICHycrK0uDBg1W7dm3CKADAKdAhBTxIZmamUlNT1bVrV0VERFhdDgAAkuiQAh4jMzNTAwcO1NatWwmjAACnQof0IsYYpaSkOG4nJydbWA1QusaPH68777xTd9xxh9WlAACQA4H0/xhjFB4ers2bN1tdClCqMjMz9dlnn2nMmDHy8/OzuhwAAHJhyv7/pKSk5BtGw8LCZLPZyrkioOQyMjL0yCOPKDk5mTAKAHBadEjzkJiYqMDAQMdtm80mLy8vCysCiufAgQPq1KmTunXrZnUpAADkiw5pHgIDA3N8EUbhajIyMjRgwABVrlyZMAoAcHoEUsDNGGM0YMAA3X333apRo4bV5QAAcFlM2QNuxG63648//tDLL7+sOnXqWF0OAACFQocUcBN2u119+vTRDz/8QBgFALgUAingJpYvX66HHnpIXbp0sboUAACKhCl7wMWlp6dr0qRJGjdunLy9+RsTAOB6+O0FuLD09HT17t1bt9xyC2EUAOCy6JACLio9PV1paWkaNmyY2rRpY3U5AAAUGy0VwAWlpaWpV69e2rNnD2EUAODyCKSACxo1apT69eunW2+91epSAAAoMabsAReSmpqq1atX69VXX1WFCrx9AQDugQ4p4CJSU1PVs2dP2Ww2wigAwK3wWw1wEb/++qsGDx6siIgIq0sBAKBUeWyH1Bij5OTkHF+AM7pw4YK6d++uq6++mjAKAHBLHhlIjTEKDw9XUFCQ46t69epWlwXkkpWVpV69emnAgAEKCQmxuhwAAMqER07Zp6SkaPPmzXl+LywsTDabrZwrAnJLSUlRQkKCZs6cqRo1alhdDgAAZcYjO6QXS0xM1Pnz5x1fX331lby8vKwuCx4uJSVFPXr00G+//UYYBQC4PY/skF4sMDBQgYGBVpcB5BATE6OnnnpKd9xxh9WlAABQ5jw+kALOJDk5Wa+88opefvllOvUAAI/h8VP2gLNITk5WZGSkOnbsSBgFAHgUOqSAE0hJSVFmZqZeeukltWjRwupyAAAoV3RIAYudP39eDz30kP7880/CKADAIxFIAYs9//zzGjVqlG644QarSwEAwBJM2QMWOXfunNatW6cZM2bI25u/DQEAnovfgoAFkpKS1K1bN9WqVYswCgDweHRIgXJmjNGePXs0btw4/fOf/7S6HAAALEdrBihHZ8+e1QMPPKAmTZoQRgEA+D8EUqCcZGRkqHv37ho5cqRsNpvV5QAA4DSYsgfKwZkzZ3Tq1CktXrxYVatWtbocAACcCh1SoIydPn1a3bp106lTpwijAADkgQ4pUMaWLVum6OhoNW/e3OpSAABwSgRSoIycOnVKU6dO1aRJk6wuBQAAp8aUPVAGTp06pe7du6tr165WlwIAgNOjQwqUsqSkJPn4+Gj69Olq3Lix1eUAAOD06JACpejkyZN64IEHdPr0acIoAACFRCAFStHw4cM1bdo01atXz+pSAABwGUzZA6XgxIkT+vLLLzVv3jx5eXlZXQ4AAC6FDilQQsePH1f37t11/fXXE0YBACgGOqRACRhj9Ouvv+qtt97SjTfeaHU5AAC4JDqkQDElJibq/vvvV6tWrQijAACUAB1SoBhSU1PVq1cvvf322/L19bW6HAAAXBqBFCiiY8eOKS0tTStWrFBISIjV5QAA4PKYsgeK4NixY+rVq5fS0tIIowAAlBICKVAEcXFxmjVrlq6//nqrSwEAwG0wZQ8Uwp9//qlZs2bp5ZdftroUAADcDh1S4DKOHj2qPn36qF+/flaXAgCAW6JDChTgr7/+UsWKFfXuu++qQYMGVpcDAIBbokMK5OP333/XQw89pPT0dMIoAABliEAK5MEYo1GjRum9995T9erVrS4HAAC3xpQ9cInffvtN27dv16JFi/hsegAAygEdUuAihw8fVv/+/XXzzTcTRgEAKCcEUuD/ZGZm6vDhw5o/f77q1atndTkAAHgMAikg6dChQ3rggQd0++23E0YBAChnnEMKj5eUlKQBAwZo4cKF8vbmbzQAAMobgRQe7cCBA/Lz89OqVasUFBRkdTkAAHgk2kHwWPv379egQYPk7e1NGAUAwEIEUnisjz/+WIsWLVLt2rWtLgUAAI/GlD08zr59+7RkyRKNHz/e6lIAAIAIpPAw+/fv12OPPabFixdbXQoAAPg/BFJ4jISEBF1xxRVasmSJatasaXU5AADg/3AOKTzCnj171LNnT3l7exNGAQBwMgRSuD1jjCZOnKiYmBiFhIRYXQ4AALgEU/Zwa7/88osOHDigpUuXWl0KAADIBx1SuK2ff/5ZTz75pFq1amV1KQAAoAAEUriljIwMJSYmKiYmRtWqVbO6HAAAUAACKdzOrl271L17d91xxx2EUQAAXADnkMKtnDhxQlFRUVq2bJm8vLysLgcAABQCHVK4jV27dslut2vVqlWqWrWq1eUAAIBCIpDCLezcuVPPPvus/P39VbFiRavLAQAARcCUPdxCfHy8YmNjdcUVV1hdCgAAKCICKVza9u3btXr1ao0ZM8bqUgAAQDERSOGyfvjhB40cOVKxsbFWlwIAAEqAc0jhkn7//XfVqlVLsbGxqlKlitXlAACAEiCQwuV89913evTRRxUYGEgYBQDADRQrkM6YMUP16tVTQECAWrVqpa1bt+a777vvvqs2bdqoSpUqqlKlitq3b1/g/kBBMjIy9Oabb2r58uWy2WxWlwMAAEpBkQNpXFycoqKiNG7cOG3fvl1NmzZVRESEjh8/nuf+GzduVI8ePfTFF19oy5YtqlOnjjp27Kg///yzxMXDs3z77bdav369lixZosqVK1tdDgAAKCVFDqTTpk3TwIED1b9/fzVu3FizZ8+WzWbT/Pnz89x/6dKlGjJkiJo1a6ZGjRrpvffeU1ZWltavX1/i4uE5vv32W7300ktq3bq11aUAAIBSVqSr7NPT07Vt2zaNHDnSsc3b21vt27fXli1bCnUfKSkpstvtBa4XmZaWprS0NMftpKQkSZLdbpfdbndsz/7/i7cVxqX3UdTjUX6yx+fs2bNasmSJKlasyHi5oeK+l+FaGGf3xxh7hvzGuSTjXqRAevLkSWVmZqp69eo5tlevXl179uwp1H288MILqlWrltq3b5/vPtHR0Ro/fnyu7evWrcvzvMH4+PhCPXa21NRUx/+vXbtWAQEBRToe5WfPnj1avXq1oqKitGnTJqvLQRkr6nsZrolxdn+MsWe4dJxTUlKKfV/lug7p5MmTFRsbq40bNxYYAkeOHKmoqCjH7aSkJMe5p8HBwY7tdrtd8fHx6tChg3x9fQtdR3JysuP/IyIiFBgYWMRngvJw5MgRzZo1S48//niRxxiupbjvZbgWxtn9McaeIb9xzp7RLo4iBdKqVavKx8dHiYmJObYnJiaqRo0aBR77+uuva/Lkyfr888/1j3/8o8B9/f395e/vn2u7r69vni/w/Lbn5+J9i3osysc333yjBg0aaMWKFVq/fj3j5CEYZ8/AOLs/xtgzXDrOJRnzIl3U5Ofnp+bNm+e4ICn7AqWCLjZ57bXXNHHiRK1Zs0YtWrQodrHwDF9++aUmTZqkwMDAPP8wAQAA7qXIU/ZRUVHq27evWrRooZYtW2r69OlKTk5W//79JUl9+vRR7dq1FR0dLUl69dVXNXbsWMXExKhevXpKSEiQJAUFBSkoKKgUnwrcxdatWxUbG6vAwEBOjAcAwAMUOZBGRkbqxIkTGjt2rBISEtSsWTOtWbPGcaHTkSNH5O39/xuvs2bNUnp6urp27ZrjfsaNG6eXXnqpZNXDrWzcuFHfffednn/+eatLAQAA5ahYFzUNGzZMw4YNy/N7GzduzHH78OHDxXkIeJhNmzZp2rRpio2NtboUAABQzvgse1juwIEDuv766xUbG8vHgQIA4IEIpLDU559/rqioKIWEhBBGAQDwUARSWCY1NVUxMTGKjY1leRAAADxYuS6MD2Rbt26d/P39NX/+fKtLAQAAFqNDinK3du1azZ49W61atbK6FAAA4AQIpChXqamp8vPzU0xMTIEfHwsAADwHU/YoN6tXr9ZHH32kuXPnWl0KAABwIh4RSI0xSklJcdxOTk62sBrPtGfPHi1YsEBLliyxuhQAAOBk3H7K3hij8PBwx0eVBgUFOT5VCuVj/fr1Cg0N1bJly/hsegAAkIvbB9KUlBRt3rw5z++FhYWx9mUZW7VqlebMmaNKlSqpQgWPaMgDAIAi8qiEkJiYqMDAQMdtm80mLy8vCytyb8YY7d+/X0uWLJGfn5/V5QAAACflUYE0MDAwRyBF2fnoo4/0+++/KyoqyupSAACAk/OoQIrysXr1asXFxWnRokVWlwIAAFwAgRSlavfu3br11lvVoUMHPg4UAAAUittf1ITys2LFCr388su68sorCaMAAKDQCKQoFUlJSdqwYYPef/99eXvzsgIAAIXHlD1KLC4uTvXr19fMmTOtLgUAALggWlkokdjYWH322We65ZZbrC4FAAC4KAIpiu38+fOqVauW5s+fz6L3AACg2EgRKJYlS5Zo+/btmjZtmtWlAAAAF0cgRZF9//332rBhg959912rSwEAAG6AKXsUyccff6xrr71W7777rnx8fKwuBwAAuAECKQpt4cKF+vTTT1WpUiXCKAAAKDUEUhRKVlaWkpKSNGfOHNYZBQAApYpzSHFZ8+fPlyQ9+eSTFlcCAADcEa0uFGjZsmXaunWr+vXrZ3UpAADATdEhRb5++OEHdejQQZGRkUzTAwCAMkPKQJ7mzJmjuXPn6sorrySMAgCAMkXSQC4nTpzQgQMH9M4778jLy8vqcgAAgJsjkCKH2bNnKyEhQa+99hphFAAAlAsCKRxmzJih3bt3q0mTJlaXAgAAPAgXNUGSdPbsWd1yyy0aMmQInVEAAFCuCKTQm2++qTNnzmjcuHFWlwIAADwQgdTDffHFFzpy5Ihef/11q0sBAAAeikDqwZYuXaouXbqoXbt2TNMDAADLcFGTh5o6dap++OEH2Ww2wigAALAUHVIPZLfbFRwcrKioKMIoAACwHIHUw7z22muqX7++Bg4caHUpAAAAkpiy9yizZs3S2bNn1bVrV6tLAQAAcKBD6iG+++47de/eXSEhIUzTAwAAp0KH1ANMmjRJq1atUpUqVQijAADA6RBI3dyRI0ckSRMmTLC4EgAAgLwRSN1YdHS0MjIyNHr0aDqjAADAaXEOqZsaP368vLy81KBBA6tLAQAAKBCB1M0YY3Tq1Cndd999at68udXlAAAAXBaB1I0YYzR27FiFhobqySeftLocAACAQuEcUjeyatUq2Ww2wigAAHApdEjdgDFGc+fOVf/+/XX//fdbXQ4AAECR0CF1ccYYjRw5UklJSfLz87O6HAAAgCKjQ+rCjDFKTU3VTTfdpF69elldDgAAQLHQIXVRxhi98MIL+vLLLwmjAADApbl0hzS7Q5icnCxfX98890lOTi7nqspHdHS0atasqYiICKtLAQAAKBGXDaTGGLVr105btmyxupRyZYzR119/rWHDhik4ONjqcgAAAErMZafsU1JSihRGw8LCZLPZyrCismeMUVRUlLZv304YBQAAbsNlO6QX++OPPxQSElLgPjabzeU/z/3XX3/VtddeqyFDhlhdCgAAQKlx2Q7pxQIDAy/75cph1Bij4cOHKzg4mDAKAADcjlsEUndmjNFTTz2l+vXrq2bNmlaXAwAAUOrcYsreXWVlZenkyZMaNGiQmjRpYnU5AAAAZYIOqZPKysrSsGHDtHbtWsIoAABwawRSJxUTE6Obb75ZvXv3troUAACAMsWUvZPJysrSW2+9pSeffFLe3vy9AAAA3B+Jx4lkZWXpscceU3BwMGEUAAB4DDqkTiIrK0vJycnq1KmT7r//fqvLAQAAKDe04ZxAZmamBg0apJ9++okwCgAAPA6B1AmMGjVKbdu2VevWra0uBQAAoNwxZW+hzMxMffnllxo3bpxsNpvV5QAAAFiCDqlFMjMz9eijj+ro0aOEUQAA4NHokFpk165d6tixo3r06GF1KQAAAJaiQ1rOMjIy9Pjjj6tu3bqEUQAAABFIy5UxRv3791e7du1UpUoVq8sBAABwCkzZl5OMjAydPHlSY8aM0fXXX291OQAAAE6DDmk5sNvt6tu3r7777jvCKAAAwCUIpOVg/vz5euCBB9S5c2erSwEAAHA6TNmXIbvdrjfeeEPPP/+8vLy8rC4HAADAKdEhLSPp6enq3bu3rrvuOsIoAABAAeiQlgG73a6UlBQ9+uijat++vdXlAAAAODU6pKUsPT1dvXr10u+//04YBQAAKAQCaSl75pln1KdPH910001WlwIAAOASmLIvJWlpafryyy81depUBQQEWF0OAACAy6BDWgrS0tLUq1cvZWRkEEYBAACKiA5pKdi2bZseffRR3X333VaXAgAA4HLokJZAamqq+vXrp6ZNmxJGAQAAiolAWkwZGRnq0aOHevbsqcDAQKvLAQAAcFlM2RfDhQsXdPbsWU2bNk3169e3uhwAAACXRoe0iFJSUtS9e3ft3buXMAoAAFAKCKRFNHfuXD355JNq27at1aUAAAC4BabsCyk5OVlvvfWWRo4caXUpAAAAboUOaSEkJyere/fuat26tdWlAAAAuB06pJeRlpam1NRUjRo1ikAKAABQBuiQFuD8+fN68MEHdfbsWcIoAABAGSGQFmDYsGEaMWKEGjRoYHUpAAAAbosp+zycO3dOW7Zs0bvvvitfX1+rywEAAHBrdEgvce7cOUVGRiooKIgwCgAAUA7okF7iu+++04svvsg5owAAAOWEQPp/kpKS9Nhjj2nhwoXy8/OzuhwAAACPwZS9pNTUVHXr1k1PP/00YRQAAKCceXyH9MyZM0pLS9O8efNUu3Ztq8sBAADwOB7dIT1z5owiIyP1559/EkYBAAAs4tGBdM6cOZo0aZJuueUWq0sBAADwWB45ZX/69GnNnj1bI0eOtLoUAAAAj+dxHdJTp04pMjJSERERVpcCAAAAeViHNCUlRRkZGZoyZYqaNm1qdTkAAACQB3VI//rrL91///3KzMwkjAIAADgRjwmkQ4cO1euvv66aNWtaXQoAAAAu4vZT9idPntT27du1ZMkSVajg9k8XAADA5bh1h/TEiRPq3r27atWqRRgFAABwUm4bSI0x2rZtm6ZPn64mTZpYXQ4AAADy4ZaB9Pjx4+revbs6dOhAGAUAAHBybjePfe7cOfXs2VNvvfWWfHx8rC4HAAAAl+FWgTQhIUE+Pj5aunSpqlevbnU5AAAAKIRiTdnPmDFD9erVU0BAgFq1aqWtW7cWuP8HH3ygRo0aKSAgQDfddJNWr15drGILcuzYMfXq1UunT58mjAIAALiQIgfSuLg4RUVFady4cdq+fbuaNm2qiIgIHT9+PM/9N2/erB49emjAgAHasWOHunTpoi5duuinn34qcfEXmzdvnmbOnKnrrruuVO8XAAAAZavIgXTatGkaOHCg+vfvr8aNG2v27Nmy2WyaP39+nvu/+eabuvvuu/X888/rhhtu0MSJE3XLLbfonXfeKXHx2d544w2NGTNG119/fandJwAAAMpHkc4hTU9P17Zt2zRy5EjHNm9vb7Vv315btmzJ85gtW7YoKioqx7aIiAh99NFH+T5OWlqa0tLSHLeTkpIkSXa7XXa73fH/2e69994ct+E+8hpvuB/G2TMwzu6PMfYM+Y1zSca9SIH05MmTyszMzHWOZvXq1bVnz548j0lISMhz/4SEhHwfJzo6WuPHj8+1fd26dbLZbJKk1NRUx/bDhw8XeH9wffHx8VaXgHLAOHsGxtn9Mcae4dJxTklJKfZ9OeVV9iNHjszRVU1KSlKdOnXUsWNHBQcHS/p74fvjx49rw4YNuu++++Tn52dVuShDdrtd8fHx6tChg3x9fa0uB2WEcfYMjLP7Y4w9Q37jnD2jXRxFCqRVq1aVj4+PEhMTc2xPTExUjRo18jymRo0aRdpfkvz9/eXv759ru6+vb44nHhISooCAAPn5+fHCd3OXjj3cE+PsGRhn98cYe4ZLx7kkY16ki5r8/PzUvHlzrV+/3rEtKytL69evV+vWrfM8pnXr1jn2l/5u8ea3PwAAADxLkafso6Ki1LdvX7Vo0UItW7bU9OnTlZycrP79+0uS+vTpo9q1ays6OlqS9NRTT6lt27aaOnWqOnXqpNjYWH3//feaO3du6T4TAAAAuKQiB9LIyEidOHFCY8eOVUJCgpo1a6Y1a9Y4Llw6cuSIvL3/f+P1tttuU0xMjMaMGaNRo0bp2muv1UcffVSkz5g3xkjKfW6C3W5XSkqKkpKSmBpwU4yxZ2CcPQPj7P4YY8+Q3zhn57Ts3FYUXqY4R5WzP/74Q3Xq1LG6DAAAAFzG77//rquuuqpIx7hEIM3KytLRo0dVqVIleXl5ObZnX33/+++/O66+h3thjD0D4+wZGGf3xxh7hvzG2Rijc+fOqVatWjlmywvDKZd9upS3t3eBSTs4OJgXvptjjD0D4+wZGGf3xxh7hrzGuXLlysW6ryJ/dCgAAABQmgikAAAAsJRLB1J/f3+NGzcuz0X04R4YY8/AOHsGxtn9McaeoSzG2SUuagIAAID7cukOKQAAAFwfgRQAAACWIpACAADAUgRSAAAAWMrpA+mMGTNUr149BQQEqFWrVtq6dWuB+3/wwQdq1KiRAgICdNNNN2n16tXlVCmKqyhj/O6776pNmzaqUqWKqlSpovbt21/2NQHnUNT3crbY2Fh5eXmpS5cuZVsgSqyoY3zmzBkNHTpUNWvWlL+/v6677jr+zXYBRR3n6dOn6/rrr1fFihVVp04dPfPMM0pNTS2nalFUX375pTp37qxatWrJy8tLH3300WWP2bhxo2655Rb5+/vrmmuu0cKFC4v+wMaJxcbGGj8/PzN//nzz888/m4EDB5qQkBCTmJiY5/5ff/218fHxMa+99pr55ZdfzJgxY4yvr6/ZtWtXOVeOwirqGPfs2dPMmDHD7Nixw+zevdv069fPVK5c2fzxxx/lXDmKoqjjnO3QoUOmdu3apk2bNub+++8vn2JRLEUd47S0NNOiRQtz7733mk2bNplDhw6ZjRs3mp07d5Zz5SiKoo7z0qVLjb+/v1m6dKk5dOiQWbt2ralZs6Z55plnyrlyFNbq1avN6NGjzcqVK40k8+GHHxa4/8GDB43NZjNRUVHml19+MW+//bbx8fExa9asKdLjOnUgbdmypRk6dKjjdmZmpqlVq5aJjo7Oc/9u3bqZTp065djWqlUrM3jw4DKtE8VX1DG+VEZGhqlUqZJ5//33y6pElILijHNGRoa57bbbzHvvvWf69u1LIHVyRR3jWbNmmQYNGpj09PTyKhGloKjjPHToUHPnnXfm2BYVFWXCwsLKtE6UjsIE0uHDh5sbb7wxx7bIyEgTERFRpMdy2in79PR0bdu2Te3bt3ds8/b2Vvv27bVly5Y8j9myZUuO/SUpIiIi3/1hreKM8aVSUlJkt9t1xRVXlFWZKKHijvOECRNUrVo1DRgwoDzKRAkUZ4xXrVql1q1ba+jQoapevbqaNGmiV155RZmZmeVVNoqoOON82223adu2bY5p/YMHD2r16tW69957y6VmlL3Syl4VSrOo0nTy5EllZmaqevXqObZXr15de/bsyfOYhISEPPdPSEgoszpRfMUZ40u98MILqlWrVq43A5xHccZ506ZNmjdvnnbu3FkOFaKkijPGBw8e1IYNG9SrVy+tXr1a+/fv15AhQ2S32zVu3LjyKBtFVJxx7tmzp06ePKnw8HAZY5SRkaHHHntMo0aNKo+SUQ7yy15JSUm6cOGCKlasWKj7cdoOKXA5kydPVmxsrD788EMFBARYXQ5Kyblz59S7d2+9++67qlq1qtXloIxkZWWpWrVqmjt3rpo3b67IyEiNHj1as2fPtro0lKKNGzfqlVde0cyZM7V9+3atXLlSn332mSZOnGh1aXAyTtshrVq1qnx8fJSYmJhje2JiomrUqJHnMTVq1CjS/rBWccY42+uvv67Jkyfr888/1z/+8Y+yLBMlVNRxPnDggA4fPqzOnTs7tmVlZUmSKlSooL1796phw4ZlWzSKpDjv5Zo1a8rX11c+Pj6ObTfccIMSEhKUnp4uPz+/Mq0ZRVeccX7xxRfVu3dvPfroo5Kkm266ScnJyRo0aJBGjx4tb2/6Yq4uv+wVHBxc6O6o5MQdUj8/PzVv3lzr1693bMvKytL69evVunXrPI9p3bp1jv0lKT4+Pt/9Ya3ijLEkvfbaa5o4caLWrFmjFi1alEepKIGijnOjRo20a9cu7dy50/H1r3/9S3fccYd27typOnXqlGf5KITivJfDwsK0f/9+xx8bkvTrr7+qZs2ahFEnVZxxTklJyRU6s/8I+fuaGbi6UsteRbveqnzFxsYaf39/s3DhQvPLL7+YQYMGmZCQEJOQkGCMMaZ3795mxIgRjv2//vprU6FCBfP666+b3bt3m3HjxrHsk5Mr6hhPnjzZ+Pn5mRUrVphjx445vs6dO2fVU0AhFHWcL8VV9s6vqGN85MgRU6lSJTNs2DCzd+9e8+mnn5pq1aqZl19+2aqngEIo6jiPGzfOVKpUySxbtswcPHjQrFu3zjRs2NB069bNqqeAyzh37pzZsWOH2bFjh5Fkpk2bZnbs2GF+++03Y4wxI0aMML1793bsn73s0/PPP292795tZsyY4X7LPhljzNtvv22uvvpq4+fnZ1q2bGm++eYbx/fatm1r+vbtm2P/5cuXm+uuu874+fmZG2+80Xz22WflXDGKqihjXLduXSMp19e4cePKv3AUSVHfyxcjkLqGoo7x5s2bTatWrYy/v79p0KCBmTRpksnIyCjnqlFURRlnu91uXnrpJdOwYUMTEBBg6tSpY4YMGWJOnz5d/oWjUL744os8f89mj2vfvn1N27Ztcx3TrFkz4+fnZxo0aGAWLFhQ5Mf1MoaeOQAAAKzjtOeQAgAAwDMQSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAUAAICl/h8ENILSncNnQgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Based on the graph, since our ROC-AUC curve achieved an 82% prediction rate, this result can be considered as correctly classifying patients who have Pima diabetes and those who do not."
      ],
      "metadata": {
        "id": "EnCnpMfwEzaq"
      },
      "id": "EnCnpMfwEzaq"
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c69bfb2-1dab-490f-cc9e-dfa4004645e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "8b042e11-b82d-41c8-e061-2d5a74631053"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0165d4f400>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Based on the line graph, both the training and validation losses gradually decreased as the number of epochs increased, indicating that the model was performing well. However, there was a slight increase between 50 and 75 epochs, suggesting that overfitting occurred during training. Overall, the data performed well as the number of epochs increased."
      ],
      "metadata": {
        "id": "_kEZVC2_Hdow"
      },
      "id": "_kEZVC2_Hdow"
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#type your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epochs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zNwqMAzBRRV0",
        "outputId": "310d1772-40bf-405e-8e6c-a05081282695"
      },
      "id": "zNwqMAzBRRV0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6869287-fc38-4122-8e24-f970ee35e5cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6869287-fc38-4122-8e24-f970ee35e5cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6869287-fc38-4122-8e24-f970ee35e5cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6869287-fc38-4122-8e24-f970ee35e5cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1dc7ddb5-5772-4885-80e6-64b9c7e38a43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1dc7ddb5-5772-4885-80e6-64b9c7e38a43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1dc7ddb5-5772-4885-80e6-64b9c7e38a43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1].values\n",
        "y = df[\"Outcome\"].values"
      ],
      "metadata": {
        "id": "LVrgBHVTRatb"
      },
      "id": "LVrgBHVTRatb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "metadata": {
        "id": "3Fu0k8IRRchK"
      },
      "id": "3Fu0k8IRRchK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWmu5HT0RejG",
        "outputId": "c990f75f-c4a5-45e1-8442-a8982ea0e42a"
      },
      "id": "hWmu5HT0RejG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "mFbqHt9EA5NT"
      },
      "id": "mFbqHt9EA5NT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "        Dense(6, input_shape= (8,), activation=\"relu\"),\n",
        "        Dense(6, input_shape= (8,), activation=\"relu\"),\n",
        "        Dense(1, activation = 'sigmoid')]\n",
        ")"
      ],
      "metadata": {
        "id": "PIbglFLdUvBh"
      },
      "id": "PIbglFLdUvBh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGXdzgiB5R7",
        "outputId": "33513280-fd26-4ac3-d681-20b75a4b0df1"
      },
      "id": "tOGXdzgiB5R7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyvQ18lhCCxA",
        "outputId": "9ca56aff-2c7f-459a-9cac-c1111b59b435"
      },
      "id": "RyvQ18lhCCxA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.8478 - accuracy: 0.3455 - val_loss: 0.8157 - val_accuracy: 0.3490\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.3385 - val_loss: 0.7755 - val_accuracy: 0.3698\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7628 - accuracy: 0.3819 - val_loss: 0.7472 - val_accuracy: 0.4062\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.4392 - val_loss: 0.7266 - val_accuracy: 0.5052\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.5087 - val_loss: 0.7112 - val_accuracy: 0.5260\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.5451 - val_loss: 0.6995 - val_accuracy: 0.5469\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5590 - val_loss: 0.6903 - val_accuracy: 0.5677\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5816 - val_loss: 0.6830 - val_accuracy: 0.5885\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6181 - val_loss: 0.6770 - val_accuracy: 0.5990\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.6181 - val_loss: 0.6720 - val_accuracy: 0.5938\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6302 - val_loss: 0.6679 - val_accuracy: 0.6146\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6319 - val_loss: 0.6644 - val_accuracy: 0.6302\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6389 - val_loss: 0.6614 - val_accuracy: 0.6302\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6441 - val_loss: 0.6587 - val_accuracy: 0.6354\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6458 - val_loss: 0.6564 - val_accuracy: 0.6458\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6543 - val_accuracy: 0.6510\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6580 - val_loss: 0.6525 - val_accuracy: 0.6562\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6632 - val_loss: 0.6508 - val_accuracy: 0.6562\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6580 - val_loss: 0.6494 - val_accuracy: 0.6458\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6545 - val_loss: 0.6480 - val_accuracy: 0.6458\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6562 - val_loss: 0.6468 - val_accuracy: 0.6458\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6562 - val_loss: 0.6456 - val_accuracy: 0.6458\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6545 - val_loss: 0.6446 - val_accuracy: 0.6510\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6562 - val_loss: 0.6436 - val_accuracy: 0.6510\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6562 - val_loss: 0.6426 - val_accuracy: 0.6510\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6346 - accuracy: 0.6562 - val_loss: 0.6417 - val_accuracy: 0.6510\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6580 - val_loss: 0.6408 - val_accuracy: 0.6510\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6615 - val_loss: 0.6399 - val_accuracy: 0.6510\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.6615 - val_loss: 0.6391 - val_accuracy: 0.6458\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6615 - val_loss: 0.6383 - val_accuracy: 0.6458\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6615 - val_loss: 0.6374 - val_accuracy: 0.6458\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6632 - val_loss: 0.6366 - val_accuracy: 0.6458\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6632 - val_loss: 0.6357 - val_accuracy: 0.6458\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6632 - val_loss: 0.6349 - val_accuracy: 0.6458\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6632 - val_loss: 0.6341 - val_accuracy: 0.6458\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6632 - val_loss: 0.6333 - val_accuracy: 0.6458\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6632 - val_loss: 0.6324 - val_accuracy: 0.6458\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6632 - val_loss: 0.6316 - val_accuracy: 0.6458\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6632 - val_loss: 0.6308 - val_accuracy: 0.6458\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6632 - val_loss: 0.6299 - val_accuracy: 0.6458\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6649 - val_loss: 0.6289 - val_accuracy: 0.6458\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6632 - val_loss: 0.6280 - val_accuracy: 0.6458\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6649 - val_loss: 0.6271 - val_accuracy: 0.6458\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6649 - val_loss: 0.6261 - val_accuracy: 0.6458\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6667 - val_loss: 0.6251 - val_accuracy: 0.6562\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6684 - val_loss: 0.6241 - val_accuracy: 0.6562\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6684 - val_loss: 0.6231 - val_accuracy: 0.6562\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6684 - val_loss: 0.6221 - val_accuracy: 0.6615\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6684 - val_loss: 0.6210 - val_accuracy: 0.6615\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.6701 - val_loss: 0.6199 - val_accuracy: 0.6615\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6719 - val_loss: 0.6188 - val_accuracy: 0.6719\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6736 - val_loss: 0.6176 - val_accuracy: 0.6719\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6771 - val_loss: 0.6164 - val_accuracy: 0.6719\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6771 - val_loss: 0.6152 - val_accuracy: 0.6719\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6771 - val_loss: 0.6140 - val_accuracy: 0.6771\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6788 - val_loss: 0.6127 - val_accuracy: 0.6823\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6806 - val_loss: 0.6114 - val_accuracy: 0.6823\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6823 - val_loss: 0.6101 - val_accuracy: 0.6823\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6806 - val_loss: 0.6088 - val_accuracy: 0.6875\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6840 - val_loss: 0.6074 - val_accuracy: 0.6927\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6858 - val_loss: 0.6060 - val_accuracy: 0.6927\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6875 - val_loss: 0.6045 - val_accuracy: 0.6979\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6892 - val_loss: 0.6030 - val_accuracy: 0.7031\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6910 - val_loss: 0.6015 - val_accuracy: 0.7083\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.6927 - val_loss: 0.6000 - val_accuracy: 0.7083\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6997 - val_loss: 0.5984 - val_accuracy: 0.7083\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7031 - val_loss: 0.5968 - val_accuracy: 0.7135\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.7049 - val_loss: 0.5951 - val_accuracy: 0.7188\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7083 - val_loss: 0.5934 - val_accuracy: 0.7240\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7049 - val_loss: 0.5917 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7031 - val_loss: 0.5900 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7031 - val_loss: 0.5882 - val_accuracy: 0.7396\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.7031 - val_loss: 0.5865 - val_accuracy: 0.7448\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7049 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7083 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7101 - val_loss: 0.5814 - val_accuracy: 0.7604\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7101 - val_loss: 0.5797 - val_accuracy: 0.7604\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7101 - val_loss: 0.5780 - val_accuracy: 0.7604\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7101 - val_loss: 0.5763 - val_accuracy: 0.7552\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7101 - val_loss: 0.5747 - val_accuracy: 0.7552\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7101 - val_loss: 0.5730 - val_accuracy: 0.7604\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7118 - val_loss: 0.5713 - val_accuracy: 0.7604\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7118 - val_loss: 0.5696 - val_accuracy: 0.7604\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7101 - val_loss: 0.5679 - val_accuracy: 0.7604\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7153 - val_loss: 0.5663 - val_accuracy: 0.7604\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7135 - val_loss: 0.5646 - val_accuracy: 0.7552\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7170 - val_loss: 0.5630 - val_accuracy: 0.7552\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7170 - val_loss: 0.5613 - val_accuracy: 0.7552\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7188 - val_loss: 0.5597 - val_accuracy: 0.7552\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7222 - val_loss: 0.5580 - val_accuracy: 0.7604\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7257 - val_loss: 0.5565 - val_accuracy: 0.7604\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7257 - val_loss: 0.5549 - val_accuracy: 0.7604\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7292 - val_loss: 0.5533 - val_accuracy: 0.7604\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7292 - val_loss: 0.5518 - val_accuracy: 0.7604\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7326 - val_loss: 0.5503 - val_accuracy: 0.7604\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7396 - val_loss: 0.5488 - val_accuracy: 0.7604\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7396 - val_loss: 0.5473 - val_accuracy: 0.7604\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7448 - val_loss: 0.5457 - val_accuracy: 0.7604\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7413 - val_loss: 0.5441 - val_accuracy: 0.7604\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7431 - val_loss: 0.5426 - val_accuracy: 0.7604\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7431 - val_loss: 0.5411 - val_accuracy: 0.7656\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7431 - val_loss: 0.5395 - val_accuracy: 0.7656\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7465 - val_loss: 0.5380 - val_accuracy: 0.7656\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7483 - val_loss: 0.5351 - val_accuracy: 0.7708\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7517 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7535 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7517 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7569 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7604 - val_loss: 0.5283 - val_accuracy: 0.7760\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7569 - val_loss: 0.5271 - val_accuracy: 0.7708\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7622 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7639 - val_loss: 0.5246 - val_accuracy: 0.7708\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7639 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7604 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7639 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7587 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7639 - val_loss: 0.5175 - val_accuracy: 0.7708\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7656 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7639 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7674 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7656 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7639 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7674 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7656 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7674 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7674 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7674 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7656 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7656 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7639 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7656 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7674 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7674 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7674 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7656 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7656 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7830 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7830 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7865 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7899 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7899 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7899 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7899 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7899 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7899 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7951 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7951 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7917 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7448\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7917 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7917 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7917 - val_loss: 0.4946 - val_accuracy: 0.7448\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7917 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7899 - val_loss: 0.4947 - val_accuracy: 0.7448\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7917 - val_loss: 0.4948 - val_accuracy: 0.7448\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7917 - val_loss: 0.4949 - val_accuracy: 0.7448\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7899 - val_loss: 0.4949 - val_accuracy: 0.7344\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7899 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.4950 - val_accuracy: 0.7448\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7917 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7899 - val_loss: 0.4951 - val_accuracy: 0.7448\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7917 - val_loss: 0.4952 - val_accuracy: 0.7448\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7344\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7344\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7396\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7899 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7344\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7344\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7344\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7344\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7344\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7344\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7344\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7899 - val_loss: 0.4959 - val_accuracy: 0.7344\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7344\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7344\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.4956 - val_accuracy: 0.7344\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7344\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.4954 - val_accuracy: 0.7344\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7344\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7344\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7344\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7899 - val_loss: 0.4951 - val_accuracy: 0.7344\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.4950 - val_accuracy: 0.7344\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.4950 - val_accuracy: 0.7344\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7344\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7344\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.4947 - val_accuracy: 0.7344\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.4946 - val_accuracy: 0.7344\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.4945 - val_accuracy: 0.7344\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7344\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7917 - val_loss: 0.4943 - val_accuracy: 0.7344\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7344\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7396\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7396\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7396\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7396\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7899 - val_loss: 0.4938 - val_accuracy: 0.7396\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7396\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7899 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7500\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7500\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7865 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.4917 - val_accuracy: 0.7500\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7865 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.4913 - val_accuracy: 0.7500\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7865 - val_loss: 0.4912 - val_accuracy: 0.7500\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7500\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.4907 - val_accuracy: 0.7500\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7830 - val_loss: 0.4905 - val_accuracy: 0.7500\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7830 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7865 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7865 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7812\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7899 - val_loss: 0.4878 - val_accuracy: 0.7812\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7865\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7934 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7934 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7934 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7934 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7934 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7899 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7865\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7917\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7865\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7865\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7917\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7865\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4879 - val_accuracy: 0.7812\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7812\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7812\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7865\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.4883 - val_accuracy: 0.7812\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.4886 - val_accuracy: 0.7812\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.4889 - val_accuracy: 0.7812\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.4890 - val_accuracy: 0.7812\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7917 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8021 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7986 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7986 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8038 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8056 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8056 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8056 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.4898 - val_accuracy: 0.7812\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.4900 - val_accuracy: 0.7812\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8056 - val_loss: 0.4900 - val_accuracy: 0.7812\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.4900 - val_accuracy: 0.7812\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8056 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8056 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8073 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.4901 - val_accuracy: 0.7812\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8073 - val_loss: 0.4901 - val_accuracy: 0.7760\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.4902 - val_accuracy: 0.7760\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.4903 - val_accuracy: 0.7760\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8073 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8056 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8073 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8056 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8056 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8056 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8090 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8090 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8090 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8108 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8090 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8108 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8108 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8125 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8108 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8108 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8125 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8073 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8125 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8142 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8125 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.4920 - val_accuracy: 0.7760\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8108 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.4919 - val_accuracy: 0.7760\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8108 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8125 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8073 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8125 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8073 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8056 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8090 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8108 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8108 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8073 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8125 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8090 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8090 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8108 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8108 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8073 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8090 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8090 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8056 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8090 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8090 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8073 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8073 - val_loss: 0.4945 - val_accuracy: 0.7812\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8108 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8090 - val_loss: 0.4947 - val_accuracy: 0.7812\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8108 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8090 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8090 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8108 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8108 - val_loss: 0.4949 - val_accuracy: 0.7812\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8056 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8038 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7812\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.4953 - val_accuracy: 0.7812\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8073 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.4956 - val_accuracy: 0.7812\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8125 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8090 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8038 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8108 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8108 - val_loss: 0.4957 - val_accuracy: 0.7812\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.4957 - val_accuracy: 0.7812\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8090 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8038 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8073 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8073 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8056 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8073 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8108 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8108 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.4961 - val_accuracy: 0.7812\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8125 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8125 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8108 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8125 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.4964 - val_accuracy: 0.7812\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8125 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8108 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8108 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8090 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8125 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8090 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.4967 - val_accuracy: 0.7812\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8108 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8142 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8108 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8125 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.4969 - val_accuracy: 0.7865\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8142 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8108 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8108 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8125 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8142 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8142 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8142 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8125 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8160 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8125 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8125 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8142 - val_loss: 0.4973 - val_accuracy: 0.7865\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.4974 - val_accuracy: 0.7865\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8177 - val_loss: 0.4974 - val_accuracy: 0.7865\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8177 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8177 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.4976 - val_accuracy: 0.7865\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8160 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8177 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8142 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8142 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8160 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8142 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8177 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.4979 - val_accuracy: 0.7760\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8108 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8177 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8160 - val_loss: 0.4978 - val_accuracy: 0.7865\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8142 - val_loss: 0.4977 - val_accuracy: 0.7812\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8177 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8177 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8177 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7865\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8142 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8160 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8177 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7865\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8160 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8160 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.4980 - val_accuracy: 0.7865\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.4980 - val_accuracy: 0.7865\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8142 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8177 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8177 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8177 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8160 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8177 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8142 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.4986 - val_accuracy: 0.7812\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.4987 - val_accuracy: 0.7865\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.4988 - val_accuracy: 0.7865\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.4992 - val_accuracy: 0.7812\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8177 - val_loss: 0.4992 - val_accuracy: 0.7865\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.4993 - val_accuracy: 0.7865\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8177 - val_loss: 0.4995 - val_accuracy: 0.7865\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.4993 - val_accuracy: 0.7917\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.4996 - val_accuracy: 0.7865\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.4998 - val_accuracy: 0.7865\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8177 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8177 - val_loss: 0.4996 - val_accuracy: 0.7917\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8194 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8194 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8177 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8177 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8177 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8194 - val_loss: 0.5011 - val_accuracy: 0.7917\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8177 - val_loss: 0.5010 - val_accuracy: 0.7969\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8194 - val_loss: 0.5013 - val_accuracy: 0.7917\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5014 - val_accuracy: 0.7917\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8194 - val_loss: 0.5014 - val_accuracy: 0.7917\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8177 - val_loss: 0.5014 - val_accuracy: 0.7917\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8194 - val_loss: 0.5016 - val_accuracy: 0.7969\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8194 - val_loss: 0.5015 - val_accuracy: 0.7969\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8194 - val_loss: 0.5016 - val_accuracy: 0.7969\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8194 - val_loss: 0.5017 - val_accuracy: 0.7969\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8194 - val_loss: 0.5018 - val_accuracy: 0.7917\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8177 - val_loss: 0.5017 - val_accuracy: 0.7969\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5018 - val_accuracy: 0.7969\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8194 - val_loss: 0.5019 - val_accuracy: 0.7969\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8194 - val_loss: 0.5021 - val_accuracy: 0.7969\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8194 - val_loss: 0.5023 - val_accuracy: 0.7969\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8212 - val_loss: 0.5022 - val_accuracy: 0.7969\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8194 - val_loss: 0.5021 - val_accuracy: 0.7969\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5022 - val_accuracy: 0.7969\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5024 - val_accuracy: 0.7969\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8177 - val_loss: 0.5023 - val_accuracy: 0.7969\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5025 - val_accuracy: 0.7969\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8212 - val_loss: 0.5028 - val_accuracy: 0.7969\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.5024 - val_accuracy: 0.7969\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5026 - val_accuracy: 0.7969\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8160 - val_loss: 0.5027 - val_accuracy: 0.7969\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8194 - val_loss: 0.5028 - val_accuracy: 0.7969\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5027 - val_accuracy: 0.7969\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5027 - val_accuracy: 0.7969\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5029 - val_accuracy: 0.7969\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8177 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5029 - val_accuracy: 0.7969\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5029 - val_accuracy: 0.7969\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8194 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8194 - val_loss: 0.5033 - val_accuracy: 0.7969\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8177 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8194 - val_loss: 0.5032 - val_accuracy: 0.7969\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8194 - val_loss: 0.5032 - val_accuracy: 0.7969\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8212 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5033 - val_accuracy: 0.7969\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.5034 - val_accuracy: 0.7969\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5034 - val_accuracy: 0.7969\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8194 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8212 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8194 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8229 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5039 - val_accuracy: 0.7969\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8194 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8194 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8212 - val_loss: 0.5040 - val_accuracy: 0.7969\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8212 - val_loss: 0.5041 - val_accuracy: 0.7969\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8194 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8212 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8212 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5037 - val_accuracy: 0.7969\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8212 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8212 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8212 - val_loss: 0.5039 - val_accuracy: 0.7969\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8229 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8194 - val_loss: 0.5040 - val_accuracy: 0.7969\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8194 - val_loss: 0.5039 - val_accuracy: 0.7969\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8229 - val_loss: 0.5041 - val_accuracy: 0.7969\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8212 - val_loss: 0.5044 - val_accuracy: 0.7969\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8194 - val_loss: 0.5041 - val_accuracy: 0.7969\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.5039 - val_accuracy: 0.7969\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.5040 - val_accuracy: 0.7969\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8229 - val_loss: 0.5042 - val_accuracy: 0.7969\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8212 - val_loss: 0.5044 - val_accuracy: 0.7969\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8212 - val_loss: 0.5043 - val_accuracy: 0.7969\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8194 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8194 - val_loss: 0.5043 - val_accuracy: 0.7969\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5041 - val_accuracy: 0.7969\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.5044 - val_accuracy: 0.7969\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5042 - val_accuracy: 0.7969\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8212 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8229 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8229 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8229 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8194 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8247 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8177 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8229 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8177 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8194 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8229 - val_loss: 0.5050 - val_accuracy: 0.7969\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8212 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8229 - val_loss: 0.5051 - val_accuracy: 0.7969\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8194 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8212 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8247 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8212 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8194 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8247 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.5052 - val_accuracy: 0.7969\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8177 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8212 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8247 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5057 - val_accuracy: 0.7969\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8247 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8212 - val_loss: 0.5057 - val_accuracy: 0.7969\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8194 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8212 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8229 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8177 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8212 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8212 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8194 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8212 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8212 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8229 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5055 - val_accuracy: 0.7969\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8264 - val_loss: 0.5057 - val_accuracy: 0.7969\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8229 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8229 - val_loss: 0.5063 - val_accuracy: 0.7969\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8247 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8247 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8247 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5063 - val_accuracy: 0.7969\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8247 - val_loss: 0.5063 - val_accuracy: 0.7969\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8247 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5060 - val_accuracy: 0.7969\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8177 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8264 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8229 - val_loss: 0.5063 - val_accuracy: 0.7969\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8247 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8264 - val_loss: 0.5066 - val_accuracy: 0.7917\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5059 - val_accuracy: 0.8021\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8229 - val_loss: 0.5059 - val_accuracy: 0.8021\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8247 - val_loss: 0.5059 - val_accuracy: 0.8021\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5064 - val_accuracy: 0.7969\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5060 - val_accuracy: 0.8021\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8229 - val_loss: 0.5062 - val_accuracy: 0.8021\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8229 - val_loss: 0.5063 - val_accuracy: 0.8021\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8247 - val_loss: 0.5065 - val_accuracy: 0.8021\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8229 - val_loss: 0.5066 - val_accuracy: 0.8021\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8247 - val_loss: 0.5072 - val_accuracy: 0.7917\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8229 - val_loss: 0.5065 - val_accuracy: 0.8021\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8247 - val_loss: 0.5069 - val_accuracy: 0.8021\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5065 - val_accuracy: 0.8021\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8247 - val_loss: 0.5065 - val_accuracy: 0.8021\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8229 - val_loss: 0.5068 - val_accuracy: 0.8021\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5069 - val_accuracy: 0.8021\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8229 - val_loss: 0.5069 - val_accuracy: 0.8021\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8247 - val_loss: 0.5067 - val_accuracy: 0.8021\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8229 - val_loss: 0.5070 - val_accuracy: 0.8021\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8212 - val_loss: 0.5068 - val_accuracy: 0.8021\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8264 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8212 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5070 - val_accuracy: 0.8021\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8229 - val_loss: 0.5068 - val_accuracy: 0.8021\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5068 - val_accuracy: 0.8021\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8247 - val_loss: 0.5071 - val_accuracy: 0.8021\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8229 - val_loss: 0.5070 - val_accuracy: 0.8021\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8247 - val_loss: 0.5070 - val_accuracy: 0.8021\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8247 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8212 - val_loss: 0.5072 - val_accuracy: 0.8021\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8212 - val_loss: 0.5071 - val_accuracy: 0.8021\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8212 - val_loss: 0.5074 - val_accuracy: 0.8021\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8229 - val_loss: 0.5071 - val_accuracy: 0.8021\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5069 - val_accuracy: 0.8021\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8247 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8212 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8212 - val_loss: 0.5077 - val_accuracy: 0.8021\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8229 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8212 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8212 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8212 - val_loss: 0.5079 - val_accuracy: 0.8021\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.8229 - val_loss: 0.5077 - val_accuracy: 0.8021\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8194 - val_loss: 0.5077 - val_accuracy: 0.8021\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5079 - val_accuracy: 0.8021\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5081 - val_accuracy: 0.7969\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8247 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8247 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8212 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8229 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8247 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8229 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8212 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8212 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8212 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8160 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8212 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8229 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8212 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8247 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8229 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8229 - val_loss: 0.5098 - val_accuracy: 0.7969\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8177 - val_loss: 0.5097 - val_accuracy: 0.7917\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8194 - val_loss: 0.5100 - val_accuracy: 0.7969\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8247 - val_loss: 0.5105 - val_accuracy: 0.8021\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5102 - val_accuracy: 0.7969\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8177 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8160 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8194 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8247 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5102 - val_accuracy: 0.7917\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5104 - val_accuracy: 0.7917\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5105 - val_accuracy: 0.7917\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8212 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5106 - val_accuracy: 0.7917\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8212 - val_loss: 0.5106 - val_accuracy: 0.7917\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8160 - val_loss: 0.5108 - val_accuracy: 0.7917\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8177 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5107 - val_accuracy: 0.7917\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8194 - val_loss: 0.5112 - val_accuracy: 0.7917\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8160 - val_loss: 0.5108 - val_accuracy: 0.7917\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8160 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8177 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8160 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8194 - val_loss: 0.5111 - val_accuracy: 0.7917\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8142 - val_loss: 0.5113 - val_accuracy: 0.7917\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8177 - val_loss: 0.5115 - val_accuracy: 0.7969\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7917\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8194 - val_loss: 0.5116 - val_accuracy: 0.7969\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5115 - val_accuracy: 0.7969\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7969\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8125 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7917\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8212 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8177 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7969\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7969\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7969\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8125 - val_loss: 0.5123 - val_accuracy: 0.7969\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7969\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7969\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8142 - val_loss: 0.5121 - val_accuracy: 0.7969\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7969\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7969\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7969\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7969\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7969\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8125 - val_loss: 0.5124 - val_accuracy: 0.7969\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7969\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7969\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8177 - val_loss: 0.5130 - val_accuracy: 0.7969\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7969\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7969\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7969\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8212 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3919 - accuracy: 0.8194 - val_loss: 0.5131 - val_accuracy: 0.7969\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8160 - val_loss: 0.5128 - val_accuracy: 0.7969\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7917\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7969\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8125 - val_loss: 0.5130 - val_accuracy: 0.7969\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8125 - val_loss: 0.5130 - val_accuracy: 0.7969\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7969\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8177 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8142 - val_loss: 0.5135 - val_accuracy: 0.7969\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8212 - val_loss: 0.5134 - val_accuracy: 0.7969\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8194 - val_loss: 0.5137 - val_accuracy: 0.7969\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8160 - val_loss: 0.5139 - val_accuracy: 0.7969\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8142 - val_loss: 0.5138 - val_accuracy: 0.7969\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8125 - val_loss: 0.5137 - val_accuracy: 0.7969\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8125 - val_loss: 0.5137 - val_accuracy: 0.7969\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8194 - val_loss: 0.5136 - val_accuracy: 0.7969\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8160 - val_loss: 0.5134 - val_accuracy: 0.7969\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8142 - val_loss: 0.5134 - val_accuracy: 0.7969\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8142 - val_loss: 0.5135 - val_accuracy: 0.7917\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7917\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8160 - val_loss: 0.5137 - val_accuracy: 0.7969\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8125 - val_loss: 0.5139 - val_accuracy: 0.7969\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8125 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8160 - val_loss: 0.5134 - val_accuracy: 0.7917\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8142 - val_loss: 0.5143 - val_accuracy: 0.7917\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8160 - val_loss: 0.5145 - val_accuracy: 0.7917\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8142 - val_loss: 0.5149 - val_accuracy: 0.7917\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8142 - val_loss: 0.5144 - val_accuracy: 0.7969\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8125 - val_loss: 0.5146 - val_accuracy: 0.7969\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8142 - val_loss: 0.5145 - val_accuracy: 0.7917\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8108 - val_loss: 0.5147 - val_accuracy: 0.7917\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8142 - val_loss: 0.5150 - val_accuracy: 0.7917\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8125 - val_loss: 0.5149 - val_accuracy: 0.7969\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8177 - val_loss: 0.5155 - val_accuracy: 0.7917\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8160 - val_loss: 0.5151 - val_accuracy: 0.7917\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8125 - val_loss: 0.5149 - val_accuracy: 0.7917\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8108 - val_loss: 0.5147 - val_accuracy: 0.7917\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8142 - val_loss: 0.5152 - val_accuracy: 0.7969\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8160 - val_loss: 0.5160 - val_accuracy: 0.7917\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8160 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8125 - val_loss: 0.5153 - val_accuracy: 0.7917\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8160 - val_loss: 0.5158 - val_accuracy: 0.7917\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8177 - val_loss: 0.5163 - val_accuracy: 0.7917\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8142 - val_loss: 0.5161 - val_accuracy: 0.7917\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8177 - val_loss: 0.5164 - val_accuracy: 0.7917\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8125 - val_loss: 0.5162 - val_accuracy: 0.7917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_x=model.predict(X_test)\n",
        "classes_x=np.argmax(predict_x,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSY4Wt0JCXcn",
        "outputId": "b12bdaca-e297-4411-87b1-4e0310169e2f"
      },
      "id": "uSY4Wt0JCXcn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4RpCu6CCaf-",
        "outputId": "738976bf-f6f7-4ab6-c95f-5114240d7761"
      },
      "id": "c4RpCu6CCaf-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on Diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "i32_gVMbIZ-2"
      },
      "id": "i32_gVMbIZ-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "1euKBhVgL5yA",
        "outputId": "354897d4-cc0b-4c57-9cd6-8af7d29151c9"
      },
      "id": "1euKBhVgL5yA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.792\n",
            "roc-auc is 0.825\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the graph, it performs well because it achieved of prediction of 82% in the AUC-ROC curve, meaning it correctly classifies patients who have and do not have diabetes."
      ],
      "metadata": {
        "id": "GCC6Ti2_MvID"
      },
      "id": "GCC6Ti2_MvID"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Mx62pS_FN8m2",
        "outputId": "512c9e06-ecb3-4be9-ea4e-5803c519d77c"
      },
      "id": "Mx62pS_FN8m2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0165a04880>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Here, I used a different dataset and adjusted the neural network; this time, it only has 6 nodes, which is much fewer compared to the procedure with 12 nodes. Based on the line graph, both the training and validation losses gradually decreased as the number of epochs increased meaning this dataset is performing well. However, the validation loss increased, indicating that the data was overfitted during training around 400 epochs."
      ],
      "metadata": {
        "id": "DwwQ5tbMSoF_"
      },
      "id": "DwwQ5tbMSoF_"
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "jg0EyW6HPf1E"
      },
      "id": "jg0EyW6HPf1E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Nueral Network with sigmoid and ReLu Activation Function\n",
        "model2 = Sequential([\n",
        "        Dense(6, input_shape= (8,), activation=\"relu\"),\n",
        "        Dense(6, input_shape= (8,), activation=\"relu\"),\n",
        "        Dense(6, input_shape= (8,), activation=\"relu\"),\n",
        "        Dense(1, activation = 'sigmoid')]\n",
        ")"
      ],
      "metadata": {
        "id": "gLrhEzEvK_jh"
      },
      "id": "gLrhEzEvK_jh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(SGD(learning_rate = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lYHYriXNOua",
        "outputId": "56c342eb-0504-40ec-94fb-a0585c200578"
      },
      "id": "9lYHYriXNOua",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.7126 - accuracy: 0.4688 - val_loss: 0.7094 - val_accuracy: 0.5208\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.4705 - val_loss: 0.7083 - val_accuracy: 0.5312\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4774 - val_loss: 0.7072 - val_accuracy: 0.5365\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.4844 - val_loss: 0.7062 - val_accuracy: 0.5260\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7074 - accuracy: 0.4878 - val_loss: 0.7052 - val_accuracy: 0.5260\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.4983 - val_loss: 0.7043 - val_accuracy: 0.5260\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.5000 - val_loss: 0.7033 - val_accuracy: 0.5365\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.5035 - val_loss: 0.7024 - val_accuracy: 0.5365\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.5035 - val_loss: 0.7015 - val_accuracy: 0.5365\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.5069 - val_loss: 0.7007 - val_accuracy: 0.5417\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.5104 - val_loss: 0.6998 - val_accuracy: 0.5469\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.5139 - val_loss: 0.6990 - val_accuracy: 0.5469\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.5122 - val_loss: 0.6982 - val_accuracy: 0.5521\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.5104 - val_loss: 0.6974 - val_accuracy: 0.5573\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.5156 - val_loss: 0.6966 - val_accuracy: 0.5573\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.5243 - val_loss: 0.6959 - val_accuracy: 0.5625\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.5295 - val_loss: 0.6952 - val_accuracy: 0.5625\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5330 - val_loss: 0.6944 - val_accuracy: 0.5677\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5399 - val_loss: 0.6937 - val_accuracy: 0.5729\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5417 - val_loss: 0.6930 - val_accuracy: 0.5729\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5434 - val_loss: 0.6923 - val_accuracy: 0.5781\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5434 - val_loss: 0.6917 - val_accuracy: 0.5781\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5486 - val_loss: 0.6910 - val_accuracy: 0.5833\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5469 - val_loss: 0.6904 - val_accuracy: 0.5833\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5556 - val_loss: 0.6897 - val_accuracy: 0.5885\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5573 - val_loss: 0.6891 - val_accuracy: 0.5885\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5625 - val_loss: 0.6885 - val_accuracy: 0.5885\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5642 - val_loss: 0.6879 - val_accuracy: 0.5833\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5677 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5694 - val_loss: 0.6868 - val_accuracy: 0.5833\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5712 - val_loss: 0.6862 - val_accuracy: 0.5833\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5729 - val_loss: 0.6857 - val_accuracy: 0.5885\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5833 - val_loss: 0.6852 - val_accuracy: 0.5885\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5816 - val_loss: 0.6846 - val_accuracy: 0.5885\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5885 - val_loss: 0.6841 - val_accuracy: 0.5885\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5885 - val_loss: 0.6836 - val_accuracy: 0.5833\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5920 - val_loss: 0.6831 - val_accuracy: 0.5833\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.5955 - val_loss: 0.6826 - val_accuracy: 0.5833\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5972 - val_loss: 0.6821 - val_accuracy: 0.5885\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5990 - val_loss: 0.6817 - val_accuracy: 0.5938\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6059 - val_loss: 0.6812 - val_accuracy: 0.5885\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.6042 - val_loss: 0.6807 - val_accuracy: 0.5885\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.6076 - val_loss: 0.6803 - val_accuracy: 0.5885\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6076 - val_loss: 0.6799 - val_accuracy: 0.5885\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6042 - val_loss: 0.6794 - val_accuracy: 0.5938\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6076 - val_loss: 0.6790 - val_accuracy: 0.5938\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6059 - val_loss: 0.6786 - val_accuracy: 0.5938\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.6042 - val_loss: 0.6782 - val_accuracy: 0.5990\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.6042 - val_loss: 0.6777 - val_accuracy: 0.5990\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6042 - val_loss: 0.6773 - val_accuracy: 0.5990\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.6042 - val_loss: 0.6769 - val_accuracy: 0.5990\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6094 - val_loss: 0.6765 - val_accuracy: 0.6042\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6111 - val_loss: 0.6762 - val_accuracy: 0.6042\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6128 - val_loss: 0.6758 - val_accuracy: 0.6042\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6128 - val_loss: 0.6754 - val_accuracy: 0.5990\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6111 - val_loss: 0.6750 - val_accuracy: 0.5990\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6111 - val_loss: 0.6747 - val_accuracy: 0.5990\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6094 - val_loss: 0.6743 - val_accuracy: 0.6094\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6111 - val_loss: 0.6739 - val_accuracy: 0.6042\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.6111 - val_loss: 0.6736 - val_accuracy: 0.6042\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6146 - val_loss: 0.6732 - val_accuracy: 0.6042\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6198 - val_loss: 0.6729 - val_accuracy: 0.6042\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6215 - val_loss: 0.6725 - val_accuracy: 0.6042\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6215 - val_loss: 0.6722 - val_accuracy: 0.6042\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6215 - val_loss: 0.6718 - val_accuracy: 0.6094\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.6250 - val_loss: 0.6715 - val_accuracy: 0.6094\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6250 - val_loss: 0.6711 - val_accuracy: 0.6094\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6267 - val_loss: 0.6708 - val_accuracy: 0.6094\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6285 - val_loss: 0.6704 - val_accuracy: 0.6094\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6267 - val_loss: 0.6700 - val_accuracy: 0.6146\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6250 - val_loss: 0.6697 - val_accuracy: 0.6146\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.6250 - val_loss: 0.6693 - val_accuracy: 0.6146\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.6267 - val_loss: 0.6690 - val_accuracy: 0.6146\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6267 - val_loss: 0.6687 - val_accuracy: 0.6146\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6302 - val_loss: 0.6683 - val_accuracy: 0.6198\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6302 - val_loss: 0.6680 - val_accuracy: 0.6250\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6337 - val_loss: 0.6676 - val_accuracy: 0.6250\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6337 - val_loss: 0.6673 - val_accuracy: 0.6250\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6337 - val_loss: 0.6670 - val_accuracy: 0.6250\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6319 - val_loss: 0.6666 - val_accuracy: 0.6250\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.6354 - val_loss: 0.6663 - val_accuracy: 0.6250\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6389 - val_loss: 0.6660 - val_accuracy: 0.6198\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6372 - val_loss: 0.6657 - val_accuracy: 0.6198\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6372 - val_loss: 0.6653 - val_accuracy: 0.6198\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.6389 - val_loss: 0.6650 - val_accuracy: 0.6198\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.6406 - val_loss: 0.6647 - val_accuracy: 0.6198\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6406 - val_loss: 0.6644 - val_accuracy: 0.6198\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6406 - val_loss: 0.6640 - val_accuracy: 0.6198\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6406 - val_loss: 0.6637 - val_accuracy: 0.6198\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6406 - val_loss: 0.6634 - val_accuracy: 0.6250\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6406 - val_loss: 0.6631 - val_accuracy: 0.6250\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6406 - val_loss: 0.6628 - val_accuracy: 0.6250\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.6406 - val_loss: 0.6625 - val_accuracy: 0.6250\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6406 - val_loss: 0.6622 - val_accuracy: 0.6250\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.6424 - val_loss: 0.6619 - val_accuracy: 0.6302\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6424 - val_loss: 0.6616 - val_accuracy: 0.6302\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6424 - val_loss: 0.6613 - val_accuracy: 0.6302\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6441 - val_loss: 0.6610 - val_accuracy: 0.6302\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6441 - val_loss: 0.6607 - val_accuracy: 0.6302\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6441 - val_loss: 0.6604 - val_accuracy: 0.6302\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6441 - val_loss: 0.6602 - val_accuracy: 0.6302\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6441 - val_loss: 0.6599 - val_accuracy: 0.6354\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6441 - val_loss: 0.6596 - val_accuracy: 0.6354\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6441 - val_loss: 0.6593 - val_accuracy: 0.6354\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6441 - val_loss: 0.6590 - val_accuracy: 0.6354\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6441 - val_loss: 0.6587 - val_accuracy: 0.6354\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6458 - val_loss: 0.6584 - val_accuracy: 0.6354\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6458 - val_loss: 0.6581 - val_accuracy: 0.6354\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6476 - val_loss: 0.6579 - val_accuracy: 0.6354\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6476 - val_loss: 0.6576 - val_accuracy: 0.6354\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6493 - val_loss: 0.6573 - val_accuracy: 0.6354\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6528 - val_loss: 0.6570 - val_accuracy: 0.6354\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6528 - val_loss: 0.6568 - val_accuracy: 0.6354\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6528 - val_loss: 0.6565 - val_accuracy: 0.6354\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6528 - val_loss: 0.6562 - val_accuracy: 0.6354\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6528 - val_loss: 0.6559 - val_accuracy: 0.6354\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6528 - val_loss: 0.6556 - val_accuracy: 0.6406\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6528 - val_loss: 0.6553 - val_accuracy: 0.6406\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6528 - val_loss: 0.6550 - val_accuracy: 0.6406\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6528 - val_loss: 0.6548 - val_accuracy: 0.6406\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6545 - val_accuracy: 0.6406\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6542 - val_accuracy: 0.6406\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6533 - val_accuracy: 0.6406\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6510 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6510 - val_loss: 0.6526 - val_accuracy: 0.6406\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6493 - val_loss: 0.6523 - val_accuracy: 0.6406\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6493 - val_loss: 0.6521 - val_accuracy: 0.6406\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6510 - val_loss: 0.6518 - val_accuracy: 0.6406\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6510 - val_loss: 0.6516 - val_accuracy: 0.6406\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6510 - val_loss: 0.6513 - val_accuracy: 0.6406\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6493 - val_loss: 0.6511 - val_accuracy: 0.6406\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6493 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6510 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6510 - val_loss: 0.6503 - val_accuracy: 0.6406\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6510 - val_loss: 0.6501 - val_accuracy: 0.6406\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6510 - val_loss: 0.6498 - val_accuracy: 0.6406\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6493 - val_loss: 0.6495 - val_accuracy: 0.6354\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6493 - val_loss: 0.6493 - val_accuracy: 0.6354\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6493 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6493 - val_loss: 0.6488 - val_accuracy: 0.6354\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6493 - val_loss: 0.6485 - val_accuracy: 0.6354\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6493 - val_loss: 0.6483 - val_accuracy: 0.6354\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6493 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6493 - val_loss: 0.6478 - val_accuracy: 0.6354\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6476 - val_loss: 0.6475 - val_accuracy: 0.6354\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6476 - val_loss: 0.6473 - val_accuracy: 0.6354\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6476 - val_loss: 0.6470 - val_accuracy: 0.6354\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6476 - val_loss: 0.6468 - val_accuracy: 0.6354\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6476 - val_loss: 0.6465 - val_accuracy: 0.6354\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6476 - val_loss: 0.6463 - val_accuracy: 0.6354\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6476 - val_loss: 0.6461 - val_accuracy: 0.6354\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6493 - val_loss: 0.6458 - val_accuracy: 0.6354\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6493 - val_loss: 0.6456 - val_accuracy: 0.6354\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6493 - val_loss: 0.6453 - val_accuracy: 0.6354\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6493 - val_loss: 0.6451 - val_accuracy: 0.6354\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.6493 - val_loss: 0.6448 - val_accuracy: 0.6354\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6493 - val_loss: 0.6446 - val_accuracy: 0.6354\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6493 - val_loss: 0.6443 - val_accuracy: 0.6354\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6493 - val_loss: 0.6441 - val_accuracy: 0.6354\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6493 - val_loss: 0.6438 - val_accuracy: 0.6354\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6493 - val_loss: 0.6436 - val_accuracy: 0.6354\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6493 - val_loss: 0.6433 - val_accuracy: 0.6354\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6510 - val_loss: 0.6431 - val_accuracy: 0.6354\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6528 - val_loss: 0.6428 - val_accuracy: 0.6354\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6528 - val_loss: 0.6426 - val_accuracy: 0.6354\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6528 - val_loss: 0.6424 - val_accuracy: 0.6354\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6545 - val_loss: 0.6421 - val_accuracy: 0.6354\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6545 - val_loss: 0.6419 - val_accuracy: 0.6354\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6545 - val_loss: 0.6417 - val_accuracy: 0.6354\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6545 - val_loss: 0.6414 - val_accuracy: 0.6354\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6545 - val_loss: 0.6412 - val_accuracy: 0.6354\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6545 - val_loss: 0.6410 - val_accuracy: 0.6354\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6545 - val_loss: 0.6408 - val_accuracy: 0.6354\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6545 - val_loss: 0.6406 - val_accuracy: 0.6354\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6545 - val_loss: 0.6404 - val_accuracy: 0.6354\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6545 - val_loss: 0.6401 - val_accuracy: 0.6354\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6545 - val_loss: 0.6399 - val_accuracy: 0.6354\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6545 - val_loss: 0.6397 - val_accuracy: 0.6406\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6545 - val_loss: 0.6395 - val_accuracy: 0.6406\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.6545 - val_loss: 0.6393 - val_accuracy: 0.6406\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6545 - val_loss: 0.6391 - val_accuracy: 0.6406\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.6545 - val_loss: 0.6389 - val_accuracy: 0.6406\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6545 - val_loss: 0.6386 - val_accuracy: 0.6406\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6545 - val_loss: 0.6384 - val_accuracy: 0.6406\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6545 - val_loss: 0.6382 - val_accuracy: 0.6406\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6545 - val_loss: 0.6380 - val_accuracy: 0.6406\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6545 - val_loss: 0.6378 - val_accuracy: 0.6406\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6545 - val_loss: 0.6376 - val_accuracy: 0.6406\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6545 - val_loss: 0.6374 - val_accuracy: 0.6406\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.6406\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6545 - val_loss: 0.6370 - val_accuracy: 0.6406\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6545 - val_loss: 0.6368 - val_accuracy: 0.6406\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.6545 - val_loss: 0.6366 - val_accuracy: 0.6406\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6545 - val_loss: 0.6364 - val_accuracy: 0.6406\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6545 - val_loss: 0.6362 - val_accuracy: 0.6458\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6545 - val_loss: 0.6360 - val_accuracy: 0.6458\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6545 - val_loss: 0.6358 - val_accuracy: 0.6458\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6545 - val_loss: 0.6356 - val_accuracy: 0.6458\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6545 - val_loss: 0.6354 - val_accuracy: 0.6458\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6528 - val_loss: 0.6352 - val_accuracy: 0.6458\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.6528 - val_loss: 0.6350 - val_accuracy: 0.6458\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6528 - val_loss: 0.6348 - val_accuracy: 0.6458\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6528 - val_loss: 0.6346 - val_accuracy: 0.6458\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6528 - val_loss: 0.6344 - val_accuracy: 0.6458\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6528 - val_loss: 0.6342 - val_accuracy: 0.6458\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6528 - val_loss: 0.6340 - val_accuracy: 0.6458\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6528 - val_loss: 0.6338 - val_accuracy: 0.6458\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6528 - val_loss: 0.6336 - val_accuracy: 0.6458\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6528 - val_loss: 0.6334 - val_accuracy: 0.6458\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6528 - val_loss: 0.6332 - val_accuracy: 0.6458\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6528 - val_loss: 0.6331 - val_accuracy: 0.6458\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6528 - val_loss: 0.6329 - val_accuracy: 0.6458\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6528 - val_loss: 0.6327 - val_accuracy: 0.6458\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6528 - val_loss: 0.6325 - val_accuracy: 0.6458\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6528 - val_loss: 0.6323 - val_accuracy: 0.6458\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6528 - val_loss: 0.6321 - val_accuracy: 0.6458\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6528 - val_loss: 0.6319 - val_accuracy: 0.6458\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6528 - val_loss: 0.6317 - val_accuracy: 0.6458\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6528 - val_loss: 0.6315 - val_accuracy: 0.6458\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6528 - val_loss: 0.6313 - val_accuracy: 0.6458\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6528 - val_loss: 0.6311 - val_accuracy: 0.6458\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6528 - val_loss: 0.6310 - val_accuracy: 0.6458\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6528 - val_loss: 0.6308 - val_accuracy: 0.6458\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6528 - val_loss: 0.6306 - val_accuracy: 0.6458\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6545 - val_loss: 0.6304 - val_accuracy: 0.6458\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6545 - val_loss: 0.6302 - val_accuracy: 0.6458\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6545 - val_loss: 0.6300 - val_accuracy: 0.6458\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6545 - val_loss: 0.6298 - val_accuracy: 0.6458\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6545 - val_loss: 0.6296 - val_accuracy: 0.6458\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6545 - val_loss: 0.6294 - val_accuracy: 0.6458\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6545 - val_loss: 0.6292 - val_accuracy: 0.6458\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6545 - val_loss: 0.6291 - val_accuracy: 0.6458\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6545 - val_loss: 0.6289 - val_accuracy: 0.6458\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6545 - val_loss: 0.6287 - val_accuracy: 0.6458\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6545 - val_loss: 0.6285 - val_accuracy: 0.6458\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6545 - val_loss: 0.6283 - val_accuracy: 0.6458\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6545 - val_loss: 0.6281 - val_accuracy: 0.6458\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6545 - val_loss: 0.6279 - val_accuracy: 0.6458\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.6528 - val_loss: 0.6277 - val_accuracy: 0.6458\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.6528 - val_loss: 0.6275 - val_accuracy: 0.6458\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.6528 - val_loss: 0.6274 - val_accuracy: 0.6458\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6528 - val_loss: 0.6272 - val_accuracy: 0.6458\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.6528 - val_loss: 0.6270 - val_accuracy: 0.6458\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6528 - val_loss: 0.6268 - val_accuracy: 0.6458\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6528 - val_loss: 0.6266 - val_accuracy: 0.6458\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.6528 - val_loss: 0.6264 - val_accuracy: 0.6458\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.6528 - val_loss: 0.6262 - val_accuracy: 0.6458\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6528 - val_loss: 0.6261 - val_accuracy: 0.6458\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.6528 - val_loss: 0.6259 - val_accuracy: 0.6458\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6109 - accuracy: 0.6545 - val_loss: 0.6257 - val_accuracy: 0.6458\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6545 - val_loss: 0.6255 - val_accuracy: 0.6458\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6545 - val_loss: 0.6253 - val_accuracy: 0.6458\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6545 - val_loss: 0.6251 - val_accuracy: 0.6458\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6545 - val_loss: 0.6250 - val_accuracy: 0.6458\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6545 - val_loss: 0.6248 - val_accuracy: 0.6458\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6545 - val_loss: 0.6246 - val_accuracy: 0.6458\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6545 - val_loss: 0.6244 - val_accuracy: 0.6458\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6545 - val_loss: 0.6242 - val_accuracy: 0.6458\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6545 - val_loss: 0.6240 - val_accuracy: 0.6458\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6545 - val_loss: 0.6238 - val_accuracy: 0.6458\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6545 - val_loss: 0.6236 - val_accuracy: 0.6458\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6545 - val_loss: 0.6234 - val_accuracy: 0.6458\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6545 - val_loss: 0.6233 - val_accuracy: 0.6458\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6545 - val_loss: 0.6231 - val_accuracy: 0.6458\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6071 - accuracy: 0.6545 - val_loss: 0.6229 - val_accuracy: 0.6458\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6545 - val_loss: 0.6227 - val_accuracy: 0.6458\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6545 - val_loss: 0.6225 - val_accuracy: 0.6406\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6223 - val_accuracy: 0.6406\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6545 - val_loss: 0.6221 - val_accuracy: 0.6406\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6545 - val_loss: 0.6219 - val_accuracy: 0.6406\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6545 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6562 - val_loss: 0.6215 - val_accuracy: 0.6406\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6562 - val_loss: 0.6213 - val_accuracy: 0.6406\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6562 - val_loss: 0.6211 - val_accuracy: 0.6406\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6562 - val_loss: 0.6209 - val_accuracy: 0.6406\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6562 - val_loss: 0.6208 - val_accuracy: 0.6406\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6562 - val_loss: 0.6206 - val_accuracy: 0.6406\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6562 - val_loss: 0.6204 - val_accuracy: 0.6406\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6562 - val_loss: 0.6202 - val_accuracy: 0.6406\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6562 - val_loss: 0.6200 - val_accuracy: 0.6406\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6562 - val_loss: 0.6198 - val_accuracy: 0.6406\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6562 - val_loss: 0.6196 - val_accuracy: 0.6406\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6562 - val_loss: 0.6194 - val_accuracy: 0.6406\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6562 - val_loss: 0.6192 - val_accuracy: 0.6406\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6562 - val_loss: 0.6190 - val_accuracy: 0.6406\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.6562 - val_loss: 0.6188 - val_accuracy: 0.6406\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6562 - val_loss: 0.6186 - val_accuracy: 0.6406\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.6562 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6562 - val_loss: 0.6183 - val_accuracy: 0.6406\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6562 - val_loss: 0.6181 - val_accuracy: 0.6406\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6562 - val_loss: 0.6179 - val_accuracy: 0.6406\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.6562 - val_loss: 0.6177 - val_accuracy: 0.6406\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6562 - val_loss: 0.6175 - val_accuracy: 0.6406\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.6562 - val_loss: 0.6173 - val_accuracy: 0.6406\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6562 - val_loss: 0.6171 - val_accuracy: 0.6406\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6562 - val_loss: 0.6169 - val_accuracy: 0.6406\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6562 - val_loss: 0.6168 - val_accuracy: 0.6406\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6562 - val_loss: 0.6166 - val_accuracy: 0.6406\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5984 - accuracy: 0.6562 - val_loss: 0.6164 - val_accuracy: 0.6406\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6562 - val_loss: 0.6162 - val_accuracy: 0.6406\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.6562 - val_loss: 0.6160 - val_accuracy: 0.6406\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6562 - val_loss: 0.6158 - val_accuracy: 0.6406\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6562 - val_loss: 0.6156 - val_accuracy: 0.6406\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6562 - val_loss: 0.6154 - val_accuracy: 0.6406\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.6562 - val_loss: 0.6152 - val_accuracy: 0.6406\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6562 - val_loss: 0.6150 - val_accuracy: 0.6406\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6562 - val_loss: 0.6148 - val_accuracy: 0.6406\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.6562 - val_loss: 0.6147 - val_accuracy: 0.6406\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.6562 - val_loss: 0.6145 - val_accuracy: 0.6406\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6562 - val_loss: 0.6143 - val_accuracy: 0.6406\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6562 - val_loss: 0.6141 - val_accuracy: 0.6406\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6562 - val_loss: 0.6139 - val_accuracy: 0.6406\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6562 - val_loss: 0.6137 - val_accuracy: 0.6406\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6562 - val_loss: 0.6136 - val_accuracy: 0.6406\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6562 - val_loss: 0.6134 - val_accuracy: 0.6406\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6562 - val_loss: 0.6132 - val_accuracy: 0.6406\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6562 - val_loss: 0.6130 - val_accuracy: 0.6406\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6562 - val_loss: 0.6128 - val_accuracy: 0.6406\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6562 - val_loss: 0.6126 - val_accuracy: 0.6406\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6562 - val_loss: 0.6125 - val_accuracy: 0.6406\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6562 - val_loss: 0.6123 - val_accuracy: 0.6406\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6562 - val_loss: 0.6121 - val_accuracy: 0.6406\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6562 - val_loss: 0.6119 - val_accuracy: 0.6406\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6562 - val_loss: 0.6117 - val_accuracy: 0.6406\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6562 - val_loss: 0.6116 - val_accuracy: 0.6406\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6562 - val_loss: 0.6114 - val_accuracy: 0.6406\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6562 - val_loss: 0.6112 - val_accuracy: 0.6406\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6562 - val_loss: 0.6110 - val_accuracy: 0.6406\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6562 - val_loss: 0.6109 - val_accuracy: 0.6406\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6562 - val_loss: 0.6107 - val_accuracy: 0.6406\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6562 - val_loss: 0.6105 - val_accuracy: 0.6406\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6562 - val_loss: 0.6103 - val_accuracy: 0.6406\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6562 - val_loss: 0.6101 - val_accuracy: 0.6406\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6562 - val_loss: 0.6100 - val_accuracy: 0.6406\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6562 - val_loss: 0.6098 - val_accuracy: 0.6406\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6562 - val_loss: 0.6096 - val_accuracy: 0.6406\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6562 - val_loss: 0.6094 - val_accuracy: 0.6406\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6562 - val_loss: 0.6092 - val_accuracy: 0.6406\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6562 - val_loss: 0.6091 - val_accuracy: 0.6406\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6562 - val_loss: 0.6089 - val_accuracy: 0.6406\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.6562 - val_loss: 0.6087 - val_accuracy: 0.6406\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6562 - val_loss: 0.6085 - val_accuracy: 0.6406\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6562 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6562 - val_loss: 0.6082 - val_accuracy: 0.6406\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6562 - val_loss: 0.6080 - val_accuracy: 0.6406\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6562 - val_loss: 0.6078 - val_accuracy: 0.6406\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6562 - val_loss: 0.6076 - val_accuracy: 0.6406\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6562 - val_loss: 0.6074 - val_accuracy: 0.6406\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6562 - val_loss: 0.6072 - val_accuracy: 0.6406\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6562 - val_loss: 0.6071 - val_accuracy: 0.6406\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6562 - val_loss: 0.6069 - val_accuracy: 0.6406\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6562 - val_loss: 0.6067 - val_accuracy: 0.6406\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6562 - val_loss: 0.6065 - val_accuracy: 0.6406\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6562 - val_loss: 0.6063 - val_accuracy: 0.6406\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6562 - val_loss: 0.6062 - val_accuracy: 0.6406\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6562 - val_loss: 0.6060 - val_accuracy: 0.6406\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.6562 - val_loss: 0.6058 - val_accuracy: 0.6406\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6562 - val_loss: 0.6056 - val_accuracy: 0.6406\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6562 - val_loss: 0.6055 - val_accuracy: 0.6406\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.6562 - val_loss: 0.6053 - val_accuracy: 0.6406\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6562 - val_loss: 0.6051 - val_accuracy: 0.6406\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6562 - val_loss: 0.6049 - val_accuracy: 0.6406\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6562 - val_loss: 0.6048 - val_accuracy: 0.6406\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.6562 - val_loss: 0.6046 - val_accuracy: 0.6406\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6562 - val_loss: 0.6044 - val_accuracy: 0.6406\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6562 - val_loss: 0.6042 - val_accuracy: 0.6406\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6562 - val_loss: 0.6041 - val_accuracy: 0.6406\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6562 - val_loss: 0.6039 - val_accuracy: 0.6406\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6562 - val_loss: 0.6037 - val_accuracy: 0.6406\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6562 - val_loss: 0.6035 - val_accuracy: 0.6406\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6562 - val_loss: 0.6034 - val_accuracy: 0.6406\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6562 - val_loss: 0.6032 - val_accuracy: 0.6406\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6562 - val_loss: 0.6030 - val_accuracy: 0.6406\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6562 - val_loss: 0.6028 - val_accuracy: 0.6406\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6562 - val_loss: 0.6027 - val_accuracy: 0.6406\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6562 - val_loss: 0.6025 - val_accuracy: 0.6406\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6562 - val_loss: 0.6023 - val_accuracy: 0.6406\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6562 - val_loss: 0.6022 - val_accuracy: 0.6406\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6562 - val_loss: 0.6020 - val_accuracy: 0.6406\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.6562 - val_loss: 0.6018 - val_accuracy: 0.6406\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6562 - val_loss: 0.6016 - val_accuracy: 0.6406\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6562 - val_loss: 0.6015 - val_accuracy: 0.6406\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.6562 - val_loss: 0.6013 - val_accuracy: 0.6406\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.6562 - val_loss: 0.6011 - val_accuracy: 0.6406\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6580 - val_loss: 0.6010 - val_accuracy: 0.6406\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6580 - val_loss: 0.6008 - val_accuracy: 0.6406\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6580 - val_loss: 0.6006 - val_accuracy: 0.6406\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6580 - val_loss: 0.6005 - val_accuracy: 0.6406\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6580 - val_loss: 0.6003 - val_accuracy: 0.6406\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6580 - val_loss: 0.6001 - val_accuracy: 0.6406\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6580 - val_loss: 0.5999 - val_accuracy: 0.6406\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6597 - val_loss: 0.5998 - val_accuracy: 0.6406\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6597 - val_loss: 0.5996 - val_accuracy: 0.6406\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.6597 - val_loss: 0.5994 - val_accuracy: 0.6406\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.6597 - val_loss: 0.5993 - val_accuracy: 0.6406\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6597 - val_loss: 0.5991 - val_accuracy: 0.6406\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6597 - val_loss: 0.5989 - val_accuracy: 0.6406\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.6597 - val_loss: 0.5988 - val_accuracy: 0.6406\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6597 - val_loss: 0.5986 - val_accuracy: 0.6406\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6597 - val_loss: 0.5984 - val_accuracy: 0.6406\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6597 - val_loss: 0.5983 - val_accuracy: 0.6406\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6597 - val_loss: 0.5981 - val_accuracy: 0.6406\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6597 - val_loss: 0.5979 - val_accuracy: 0.6406\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.6597 - val_loss: 0.5978 - val_accuracy: 0.6406\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.6597 - val_loss: 0.5976 - val_accuracy: 0.6406\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6597 - val_loss: 0.5974 - val_accuracy: 0.6406\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6597 - val_loss: 0.5973 - val_accuracy: 0.6406\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6597 - val_loss: 0.5971 - val_accuracy: 0.6406\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6597 - val_loss: 0.5970 - val_accuracy: 0.6406\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6597 - val_loss: 0.5968 - val_accuracy: 0.6406\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.6597 - val_loss: 0.5966 - val_accuracy: 0.6406\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6597 - val_loss: 0.5965 - val_accuracy: 0.6406\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.6597 - val_loss: 0.5963 - val_accuracy: 0.6406\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.6597 - val_loss: 0.5961 - val_accuracy: 0.6406\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.6597 - val_loss: 0.5960 - val_accuracy: 0.6458\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6597 - val_loss: 0.5958 - val_accuracy: 0.6458\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6597 - val_loss: 0.5957 - val_accuracy: 0.6458\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.6597 - val_loss: 0.5955 - val_accuracy: 0.6458\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6597 - val_loss: 0.5953 - val_accuracy: 0.6458\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.6597 - val_loss: 0.5952 - val_accuracy: 0.6458\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6597 - val_loss: 0.5950 - val_accuracy: 0.6458\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.6597 - val_loss: 0.5949 - val_accuracy: 0.6458\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.6597 - val_loss: 0.5947 - val_accuracy: 0.6458\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.6597 - val_loss: 0.5945 - val_accuracy: 0.6458\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.6597 - val_loss: 0.5944 - val_accuracy: 0.6458\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.6597 - val_loss: 0.5942 - val_accuracy: 0.6458\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.6597 - val_loss: 0.5941 - val_accuracy: 0.6458\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.6597 - val_loss: 0.5939 - val_accuracy: 0.6458\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.6597 - val_loss: 0.5938 - val_accuracy: 0.6458\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.6597 - val_loss: 0.5936 - val_accuracy: 0.6458\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.6597 - val_loss: 0.5934 - val_accuracy: 0.6458\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6597 - val_loss: 0.5933 - val_accuracy: 0.6458\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.6597 - val_loss: 0.5931 - val_accuracy: 0.6458\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6597 - val_loss: 0.5930 - val_accuracy: 0.6458\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.6597 - val_loss: 0.5928 - val_accuracy: 0.6458\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.6597 - val_loss: 0.5927 - val_accuracy: 0.6458\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.6597 - val_loss: 0.5925 - val_accuracy: 0.6458\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.6597 - val_loss: 0.5924 - val_accuracy: 0.6458\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6597 - val_loss: 0.5922 - val_accuracy: 0.6458\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.6597 - val_loss: 0.5921 - val_accuracy: 0.6458\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6597 - val_loss: 0.5919 - val_accuracy: 0.6458\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.6597 - val_loss: 0.5918 - val_accuracy: 0.6458\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.6597 - val_loss: 0.5916 - val_accuracy: 0.6458\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.6597 - val_loss: 0.5915 - val_accuracy: 0.6458\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.6597 - val_loss: 0.5913 - val_accuracy: 0.6458\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.6597 - val_loss: 0.5912 - val_accuracy: 0.6458\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.6597 - val_loss: 0.5910 - val_accuracy: 0.6458\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.6597 - val_loss: 0.5909 - val_accuracy: 0.6458\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6597 - val_loss: 0.5907 - val_accuracy: 0.6458\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.6597 - val_loss: 0.5906 - val_accuracy: 0.6458\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.6597 - val_loss: 0.5904 - val_accuracy: 0.6458\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.6597 - val_loss: 0.5903 - val_accuracy: 0.6458\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6597 - val_loss: 0.5901 - val_accuracy: 0.6458\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.6597 - val_loss: 0.5900 - val_accuracy: 0.6458\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6597 - val_loss: 0.5898 - val_accuracy: 0.6458\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.6597 - val_loss: 0.5897 - val_accuracy: 0.6458\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6597 - val_loss: 0.5896 - val_accuracy: 0.6458\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.6597 - val_loss: 0.5894 - val_accuracy: 0.6458\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.6597 - val_loss: 0.5893 - val_accuracy: 0.6458\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.6597 - val_loss: 0.5891 - val_accuracy: 0.6458\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.6597 - val_loss: 0.5890 - val_accuracy: 0.6458\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.6597 - val_loss: 0.5889 - val_accuracy: 0.6458\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.6597 - val_loss: 0.5887 - val_accuracy: 0.6458\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.6597 - val_loss: 0.5886 - val_accuracy: 0.6458\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.6597 - val_loss: 0.5885 - val_accuracy: 0.6458\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.6597 - val_loss: 0.5883 - val_accuracy: 0.6458\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.6597 - val_loss: 0.5882 - val_accuracy: 0.6458\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.6597 - val_loss: 0.5880 - val_accuracy: 0.6458\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.6597 - val_loss: 0.5879 - val_accuracy: 0.6458\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.6597 - val_loss: 0.5878 - val_accuracy: 0.6458\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.6597 - val_loss: 0.5876 - val_accuracy: 0.6458\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.6597 - val_loss: 0.5875 - val_accuracy: 0.6458\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.6597 - val_loss: 0.5874 - val_accuracy: 0.6458\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.6597 - val_loss: 0.5872 - val_accuracy: 0.6458\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.6597 - val_loss: 0.5871 - val_accuracy: 0.6458\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.6597 - val_loss: 0.5870 - val_accuracy: 0.6458\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.6597 - val_loss: 0.5869 - val_accuracy: 0.6458\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.6597 - val_loss: 0.5867 - val_accuracy: 0.6458\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.6597 - val_loss: 0.5866 - val_accuracy: 0.6458\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.6597 - val_loss: 0.5865 - val_accuracy: 0.6458\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.6597 - val_loss: 0.5863 - val_accuracy: 0.6458\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.6597 - val_loss: 0.5862 - val_accuracy: 0.6458\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.6597 - val_loss: 0.5861 - val_accuracy: 0.6458\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.6597 - val_loss: 0.5859 - val_accuracy: 0.6458\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.6597 - val_loss: 0.5858 - val_accuracy: 0.6458\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.6597 - val_loss: 0.5857 - val_accuracy: 0.6458\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.6597 - val_loss: 0.5855 - val_accuracy: 0.6458\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.6597 - val_loss: 0.5854 - val_accuracy: 0.6458\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.6615 - val_loss: 0.5853 - val_accuracy: 0.6458\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.6615 - val_loss: 0.5851 - val_accuracy: 0.6458\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.6615 - val_loss: 0.5850 - val_accuracy: 0.6458\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.6615 - val_loss: 0.5849 - val_accuracy: 0.6458\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.6615 - val_loss: 0.5848 - val_accuracy: 0.6458\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.6615 - val_loss: 0.5846 - val_accuracy: 0.6458\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5542 - accuracy: 0.6615 - val_loss: 0.5845 - val_accuracy: 0.6458\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.5540 - accuracy: 0.6615 - val_loss: 0.5844 - val_accuracy: 0.6458\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5539 - accuracy: 0.6615 - val_loss: 0.5842 - val_accuracy: 0.6458\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.6615 - val_loss: 0.5841 - val_accuracy: 0.6458\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.6615 - val_loss: 0.5840 - val_accuracy: 0.6458\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.6615 - val_loss: 0.5839 - val_accuracy: 0.6458\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.6615 - val_loss: 0.5837 - val_accuracy: 0.6458\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.6615 - val_loss: 0.5836 - val_accuracy: 0.6458\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.6615 - val_loss: 0.5835 - val_accuracy: 0.6458\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.6615 - val_loss: 0.5833 - val_accuracy: 0.6458\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.6615 - val_loss: 0.5832 - val_accuracy: 0.6458\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.6615 - val_loss: 0.5831 - val_accuracy: 0.6458\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.6615 - val_loss: 0.5830 - val_accuracy: 0.6458\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.6615 - val_loss: 0.5828 - val_accuracy: 0.6458\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.6615 - val_loss: 0.5827 - val_accuracy: 0.6458\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.6615 - val_loss: 0.5826 - val_accuracy: 0.6458\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.6615 - val_loss: 0.5824 - val_accuracy: 0.6458\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.6615 - val_loss: 0.5823 - val_accuracy: 0.6458\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.6615 - val_loss: 0.5822 - val_accuracy: 0.6458\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.6615 - val_loss: 0.5821 - val_accuracy: 0.6458\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.6615 - val_loss: 0.5819 - val_accuracy: 0.6458\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.6615 - val_loss: 0.5818 - val_accuracy: 0.6458\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.6615 - val_loss: 0.5817 - val_accuracy: 0.6458\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.6615 - val_loss: 0.5816 - val_accuracy: 0.6458\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.6615 - val_loss: 0.5814 - val_accuracy: 0.6458\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.6615 - val_loss: 0.5813 - val_accuracy: 0.6458\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.6615 - val_loss: 0.5812 - val_accuracy: 0.6458\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.6615 - val_loss: 0.5811 - val_accuracy: 0.6458\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.6615 - val_loss: 0.5809 - val_accuracy: 0.6458\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.6615 - val_loss: 0.5808 - val_accuracy: 0.6458\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.6615 - val_loss: 0.5807 - val_accuracy: 0.6458\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.6615 - val_loss: 0.5806 - val_accuracy: 0.6458\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.6615 - val_loss: 0.5804 - val_accuracy: 0.6458\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.6615 - val_loss: 0.5803 - val_accuracy: 0.6458\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.6615 - val_loss: 0.5802 - val_accuracy: 0.6458\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.6615 - val_loss: 0.5801 - val_accuracy: 0.6458\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.6615 - val_loss: 0.5800 - val_accuracy: 0.6458\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.6615 - val_loss: 0.5798 - val_accuracy: 0.6458\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.6615 - val_loss: 0.5797 - val_accuracy: 0.6458\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.6615 - val_loss: 0.5796 - val_accuracy: 0.6458\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.6615 - val_loss: 0.5795 - val_accuracy: 0.6458\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.6615 - val_loss: 0.5794 - val_accuracy: 0.6458\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.6615 - val_loss: 0.5792 - val_accuracy: 0.6458\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.6615 - val_loss: 0.5791 - val_accuracy: 0.6458\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.6615 - val_loss: 0.5790 - val_accuracy: 0.6458\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.6615 - val_loss: 0.5789 - val_accuracy: 0.6458\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.6615 - val_loss: 0.5788 - val_accuracy: 0.6458\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.6615 - val_loss: 0.5786 - val_accuracy: 0.6458\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.6615 - val_loss: 0.5785 - val_accuracy: 0.6458\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.6615 - val_loss: 0.5784 - val_accuracy: 0.6458\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.6632 - val_loss: 0.5783 - val_accuracy: 0.6458\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.6632 - val_loss: 0.5781 - val_accuracy: 0.6458\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.6632 - val_loss: 0.5780 - val_accuracy: 0.6458\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.6632 - val_loss: 0.5779 - val_accuracy: 0.6458\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.6632 - val_loss: 0.5778 - val_accuracy: 0.6458\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.6632 - val_loss: 0.5777 - val_accuracy: 0.6458\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.6632 - val_loss: 0.5775 - val_accuracy: 0.6458\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.6632 - val_loss: 0.5774 - val_accuracy: 0.6458\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.6615 - val_loss: 0.5773 - val_accuracy: 0.6458\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.6615 - val_loss: 0.5772 - val_accuracy: 0.6458\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.6615 - val_loss: 0.5771 - val_accuracy: 0.6458\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.6597 - val_loss: 0.5770 - val_accuracy: 0.6458\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.6597 - val_loss: 0.5768 - val_accuracy: 0.6458\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.6597 - val_loss: 0.5767 - val_accuracy: 0.6458\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.6597 - val_loss: 0.5766 - val_accuracy: 0.6458\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.6615 - val_loss: 0.5765 - val_accuracy: 0.6458\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.6615 - val_loss: 0.5764 - val_accuracy: 0.6458\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.6615 - val_loss: 0.5763 - val_accuracy: 0.6458\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.6615 - val_loss: 0.5762 - val_accuracy: 0.6458\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.6615 - val_loss: 0.5760 - val_accuracy: 0.6458\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.6597 - val_loss: 0.5759 - val_accuracy: 0.6458\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.6597 - val_loss: 0.5758 - val_accuracy: 0.6458\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.6597 - val_loss: 0.5757 - val_accuracy: 0.6458\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.6597 - val_loss: 0.5756 - val_accuracy: 0.6458\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.6597 - val_loss: 0.5754 - val_accuracy: 0.6458\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.6615 - val_loss: 0.5753 - val_accuracy: 0.6458\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.6615 - val_loss: 0.5752 - val_accuracy: 0.6458\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.6632 - val_loss: 0.5750 - val_accuracy: 0.6458\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.6632 - val_loss: 0.5749 - val_accuracy: 0.6458\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.6615 - val_loss: 0.5748 - val_accuracy: 0.6458\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.6615 - val_loss: 0.5747 - val_accuracy: 0.6458\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.6615 - val_loss: 0.5745 - val_accuracy: 0.6458\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.6615 - val_loss: 0.5744 - val_accuracy: 0.6458\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.6597 - val_loss: 0.5743 - val_accuracy: 0.6458\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.6597 - val_loss: 0.5741 - val_accuracy: 0.6458\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.6597 - val_loss: 0.5740 - val_accuracy: 0.6458\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.6597 - val_loss: 0.5739 - val_accuracy: 0.6458\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.6632 - val_loss: 0.5738 - val_accuracy: 0.6458\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.6632 - val_loss: 0.5736 - val_accuracy: 0.6458\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.6632 - val_loss: 0.5735 - val_accuracy: 0.6458\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.6632 - val_loss: 0.5734 - val_accuracy: 0.6458\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.6632 - val_loss: 0.5733 - val_accuracy: 0.6458\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.6632 - val_loss: 0.5731 - val_accuracy: 0.6458\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.6615 - val_loss: 0.5730 - val_accuracy: 0.6458\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.6597 - val_loss: 0.5729 - val_accuracy: 0.6458\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.6615 - val_loss: 0.5727 - val_accuracy: 0.6458\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.6615 - val_loss: 0.5726 - val_accuracy: 0.6458\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.6615 - val_loss: 0.5725 - val_accuracy: 0.6458\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.6615 - val_loss: 0.5724 - val_accuracy: 0.6458\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.6615 - val_loss: 0.5722 - val_accuracy: 0.6458\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.6615 - val_loss: 0.5721 - val_accuracy: 0.6458\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.6615 - val_loss: 0.5720 - val_accuracy: 0.6458\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.6615 - val_loss: 0.5719 - val_accuracy: 0.6458\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.6615 - val_loss: 0.5717 - val_accuracy: 0.6458\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.6615 - val_loss: 0.5716 - val_accuracy: 0.6510\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.6615 - val_loss: 0.5715 - val_accuracy: 0.6510\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.6615 - val_loss: 0.5714 - val_accuracy: 0.6510\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.6615 - val_loss: 0.5713 - val_accuracy: 0.6510\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.6615 - val_loss: 0.5711 - val_accuracy: 0.6510\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.6615 - val_loss: 0.5710 - val_accuracy: 0.6510\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.6615 - val_loss: 0.5709 - val_accuracy: 0.6510\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.6615 - val_loss: 0.5708 - val_accuracy: 0.6510\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.6632 - val_loss: 0.5706 - val_accuracy: 0.6510\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.6649 - val_loss: 0.5705 - val_accuracy: 0.6510\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.6649 - val_loss: 0.5704 - val_accuracy: 0.6510\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.6649 - val_loss: 0.5703 - val_accuracy: 0.6510\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.6667 - val_loss: 0.5701 - val_accuracy: 0.6510\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.6667 - val_loss: 0.5700 - val_accuracy: 0.6510\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.6667 - val_loss: 0.5699 - val_accuracy: 0.6510\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.6667 - val_loss: 0.5697 - val_accuracy: 0.6510\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.6667 - val_loss: 0.5696 - val_accuracy: 0.6510\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.6667 - val_loss: 0.5695 - val_accuracy: 0.6510\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.6667 - val_loss: 0.5694 - val_accuracy: 0.6510\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.6667 - val_loss: 0.5692 - val_accuracy: 0.6510\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.6667 - val_loss: 0.5691 - val_accuracy: 0.6510\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.6667 - val_loss: 0.5690 - val_accuracy: 0.6510\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.6667 - val_loss: 0.5688 - val_accuracy: 0.6510\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.6684 - val_loss: 0.5687 - val_accuracy: 0.6510\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.6684 - val_loss: 0.5686 - val_accuracy: 0.6510\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.6701 - val_loss: 0.5684 - val_accuracy: 0.6510\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.6701 - val_loss: 0.5683 - val_accuracy: 0.6510\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.6701 - val_loss: 0.5682 - val_accuracy: 0.6510\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.6701 - val_loss: 0.5680 - val_accuracy: 0.6510\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.6701 - val_loss: 0.5679 - val_accuracy: 0.6510\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.6719 - val_loss: 0.5678 - val_accuracy: 0.6510\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.6719 - val_loss: 0.5677 - val_accuracy: 0.6510\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.6719 - val_loss: 0.5675 - val_accuracy: 0.6510\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.6719 - val_loss: 0.5674 - val_accuracy: 0.6562\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.6736 - val_loss: 0.5673 - val_accuracy: 0.6562\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.6736 - val_loss: 0.5672 - val_accuracy: 0.6562\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.6753 - val_loss: 0.5671 - val_accuracy: 0.6562\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.6753 - val_loss: 0.5669 - val_accuracy: 0.6562\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.6753 - val_loss: 0.5668 - val_accuracy: 0.6562\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.6771 - val_loss: 0.5667 - val_accuracy: 0.6562\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.6771 - val_loss: 0.5665 - val_accuracy: 0.6562\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.6771 - val_loss: 0.5664 - val_accuracy: 0.6562\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.6771 - val_loss: 0.5663 - val_accuracy: 0.6562\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.6788 - val_loss: 0.5661 - val_accuracy: 0.6562\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.6771 - val_loss: 0.5660 - val_accuracy: 0.6562\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.6806 - val_loss: 0.5659 - val_accuracy: 0.6562\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.6806 - val_loss: 0.5657 - val_accuracy: 0.6615\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.6806 - val_loss: 0.5656 - val_accuracy: 0.6667\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.6806 - val_loss: 0.5654 - val_accuracy: 0.6667\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.6823 - val_loss: 0.5653 - val_accuracy: 0.6667\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.6823 - val_loss: 0.5652 - val_accuracy: 0.6667\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.6823 - val_loss: 0.5650 - val_accuracy: 0.6667\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.6823 - val_loss: 0.5649 - val_accuracy: 0.6667\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.6823 - val_loss: 0.5647 - val_accuracy: 0.6667\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.6788 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.6788 - val_loss: 0.5645 - val_accuracy: 0.6667\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.6771 - val_loss: 0.5643 - val_accuracy: 0.6667\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.6771 - val_loss: 0.5642 - val_accuracy: 0.6667\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.6788 - val_loss: 0.5641 - val_accuracy: 0.6667\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.6788 - val_loss: 0.5639 - val_accuracy: 0.6719\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.6788 - val_loss: 0.5638 - val_accuracy: 0.6719\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.6788 - val_loss: 0.5637 - val_accuracy: 0.6719\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.6788 - val_loss: 0.5635 - val_accuracy: 0.6719\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.6788 - val_loss: 0.5634 - val_accuracy: 0.6719\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.6788 - val_loss: 0.5632 - val_accuracy: 0.6719\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.6788 - val_loss: 0.5631 - val_accuracy: 0.6667\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.6823 - val_loss: 0.5630 - val_accuracy: 0.6667\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.6840 - val_loss: 0.5628 - val_accuracy: 0.6667\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.6840 - val_loss: 0.5627 - val_accuracy: 0.6667\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.6840 - val_loss: 0.5626 - val_accuracy: 0.6667\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.6875 - val_loss: 0.5624 - val_accuracy: 0.6615\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.6875 - val_loss: 0.5623 - val_accuracy: 0.6615\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.6875 - val_loss: 0.5622 - val_accuracy: 0.6615\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.6875 - val_loss: 0.5621 - val_accuracy: 0.6562\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.6875 - val_loss: 0.5619 - val_accuracy: 0.6562\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.6875 - val_loss: 0.5618 - val_accuracy: 0.6562\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.6875 - val_loss: 0.5617 - val_accuracy: 0.6562\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.6892 - val_loss: 0.5616 - val_accuracy: 0.6562\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.6892 - val_loss: 0.5614 - val_accuracy: 0.6562\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.6875 - val_loss: 0.5613 - val_accuracy: 0.6562\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.6892 - val_loss: 0.5612 - val_accuracy: 0.6562\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.6892 - val_loss: 0.5611 - val_accuracy: 0.6615\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.6892 - val_loss: 0.5609 - val_accuracy: 0.6667\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.6910 - val_loss: 0.5608 - val_accuracy: 0.6667\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.6910 - val_loss: 0.5607 - val_accuracy: 0.6667\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.6910 - val_loss: 0.5606 - val_accuracy: 0.6667\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.6927 - val_loss: 0.5604 - val_accuracy: 0.6667\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.6927 - val_loss: 0.5603 - val_accuracy: 0.6667\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.6979 - val_loss: 0.5602 - val_accuracy: 0.6667\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.6962 - val_loss: 0.5601 - val_accuracy: 0.6667\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.6962 - val_loss: 0.5600 - val_accuracy: 0.6667\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.6962 - val_loss: 0.5599 - val_accuracy: 0.6667\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.6979 - val_loss: 0.5597 - val_accuracy: 0.6667\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.6979 - val_loss: 0.5596 - val_accuracy: 0.6667\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7014 - val_loss: 0.5595 - val_accuracy: 0.6667\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.6997 - val_loss: 0.5594 - val_accuracy: 0.6667\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7014 - val_loss: 0.5593 - val_accuracy: 0.6667\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7014 - val_loss: 0.5591 - val_accuracy: 0.6719\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7014 - val_loss: 0.5590 - val_accuracy: 0.6719\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7014 - val_loss: 0.5588 - val_accuracy: 0.6771\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7014 - val_loss: 0.5587 - val_accuracy: 0.6771\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7014 - val_loss: 0.5586 - val_accuracy: 0.6771\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.7014 - val_loss: 0.5584 - val_accuracy: 0.6771\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7014 - val_loss: 0.5583 - val_accuracy: 0.6771\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7014 - val_loss: 0.5581 - val_accuracy: 0.6771\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7014 - val_loss: 0.5579 - val_accuracy: 0.6771\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7031 - val_loss: 0.5578 - val_accuracy: 0.6771\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.6979 - val_loss: 0.5576 - val_accuracy: 0.6771\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.6962 - val_loss: 0.5574 - val_accuracy: 0.6771\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.6944 - val_loss: 0.5573 - val_accuracy: 0.6771\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.6927 - val_loss: 0.5571 - val_accuracy: 0.6771\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.6927 - val_loss: 0.5569 - val_accuracy: 0.6771\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.6927 - val_loss: 0.5567 - val_accuracy: 0.6771\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.6944 - val_loss: 0.5565 - val_accuracy: 0.6771\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.6944 - val_loss: 0.5563 - val_accuracy: 0.6771\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.6944 - val_loss: 0.5561 - val_accuracy: 0.6771\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.6944 - val_loss: 0.5559 - val_accuracy: 0.6771\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.6944 - val_loss: 0.5557 - val_accuracy: 0.6771\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.6927 - val_loss: 0.5555 - val_accuracy: 0.6823\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.6944 - val_loss: 0.5553 - val_accuracy: 0.6875\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.6962 - val_loss: 0.5551 - val_accuracy: 0.6875\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.6979 - val_loss: 0.5549 - val_accuracy: 0.6875\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.6962 - val_loss: 0.5547 - val_accuracy: 0.6927\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.6962 - val_loss: 0.5545 - val_accuracy: 0.6979\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.6979 - val_loss: 0.5543 - val_accuracy: 0.7031\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.6997 - val_loss: 0.5541 - val_accuracy: 0.7031\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.6997 - val_loss: 0.5539 - val_accuracy: 0.7031\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7014 - val_loss: 0.5536 - val_accuracy: 0.7031\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7031 - val_loss: 0.5534 - val_accuracy: 0.7031\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7083 - val_loss: 0.5532 - val_accuracy: 0.7031\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7083 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7101 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7101 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7153 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7170 - val_loss: 0.5521 - val_accuracy: 0.7135\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7170 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7170 - val_loss: 0.5516 - val_accuracy: 0.7135\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7222 - val_loss: 0.5514 - val_accuracy: 0.7135\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7240 - val_loss: 0.5512 - val_accuracy: 0.7135\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7274 - val_loss: 0.5510 - val_accuracy: 0.7135\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7274 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7309 - val_loss: 0.5505 - val_accuracy: 0.7188\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7274 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7292 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7240 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7240 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7292 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7326 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7344 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7344 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7326 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7344 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7361 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7361 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7378 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7413 - val_loss: 0.5474 - val_accuracy: 0.7188\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7465 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7465 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7465 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7465 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7448 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7431 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7431 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7413 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7431 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7431 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7431 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7448 - val_loss: 0.5449 - val_accuracy: 0.7292\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7448 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7448 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7483 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7483 - val_loss: 0.5440 - val_accuracy: 0.7292\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7465 - val_loss: 0.5438 - val_accuracy: 0.7292\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7448 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7500 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7517 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7500 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7500 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7483 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7483 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7483 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7483 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7465 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7465 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7465 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7465 - val_loss: 0.5415 - val_accuracy: 0.7344\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7483 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7465 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7465 - val_loss: 0.5410 - val_accuracy: 0.7344\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7483 - val_loss: 0.5408 - val_accuracy: 0.7396\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7483 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7483 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7483 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7483 - val_loss: 0.5401 - val_accuracy: 0.7396\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.7396\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7465 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7465 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7465 - val_loss: 0.5395 - val_accuracy: 0.7448\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7448 - val_loss: 0.5393 - val_accuracy: 0.7448\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7448 - val_loss: 0.5392 - val_accuracy: 0.7448\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7448 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7448 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7448 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7465 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7465 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7465 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7483 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7483 - val_loss: 0.5380 - val_accuracy: 0.7240\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7500 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7535 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7535 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7535 - val_loss: 0.5375 - val_accuracy: 0.7135\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7552 - val_loss: 0.5373 - val_accuracy: 0.7135\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7587 - val_loss: 0.5372 - val_accuracy: 0.7135\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7587 - val_loss: 0.5370 - val_accuracy: 0.7135\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7587 - val_loss: 0.5369 - val_accuracy: 0.7135\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7587 - val_loss: 0.5368 - val_accuracy: 0.7135\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7604 - val_loss: 0.5366 - val_accuracy: 0.7135\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7604 - val_loss: 0.5365 - val_accuracy: 0.7240\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7587 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7604 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7587 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7604 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7656 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5358 - val_accuracy: 0.7135\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5357 - val_accuracy: 0.7135\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7622 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7604 - val_loss: 0.5354 - val_accuracy: 0.7135\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7604 - val_loss: 0.5353 - val_accuracy: 0.7135\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7604 - val_loss: 0.5352 - val_accuracy: 0.7135\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5351 - val_accuracy: 0.7188\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7622 - val_loss: 0.5350 - val_accuracy: 0.7188\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.5349 - val_accuracy: 0.7135\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7622 - val_loss: 0.5348 - val_accuracy: 0.7135\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7622 - val_loss: 0.5347 - val_accuracy: 0.7135\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5346 - val_accuracy: 0.7135\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7604 - val_loss: 0.5345 - val_accuracy: 0.7135\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7604 - val_loss: 0.5344 - val_accuracy: 0.7135\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7604 - val_loss: 0.5343 - val_accuracy: 0.7135\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7604 - val_loss: 0.5342 - val_accuracy: 0.7135\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7604 - val_loss: 0.5341 - val_accuracy: 0.7135\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7604 - val_loss: 0.5340 - val_accuracy: 0.7135\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7604 - val_loss: 0.5339 - val_accuracy: 0.7135\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7604 - val_loss: 0.5338 - val_accuracy: 0.7135\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7604 - val_loss: 0.5337 - val_accuracy: 0.7135\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.5336 - val_accuracy: 0.7135\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7622 - val_loss: 0.5336 - val_accuracy: 0.7135\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7622 - val_loss: 0.5335 - val_accuracy: 0.7135\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.5334 - val_accuracy: 0.7135\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7622 - val_loss: 0.5333 - val_accuracy: 0.7135\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7604 - val_loss: 0.5332 - val_accuracy: 0.7135\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7604 - val_loss: 0.5331 - val_accuracy: 0.7188\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7604 - val_loss: 0.5330 - val_accuracy: 0.7188\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7604 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7604 - val_loss: 0.5328 - val_accuracy: 0.7188\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7604 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7604 - val_loss: 0.5327 - val_accuracy: 0.7188\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7604 - val_loss: 0.5326 - val_accuracy: 0.7188\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7604 - val_loss: 0.5325 - val_accuracy: 0.7188\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5323 - val_accuracy: 0.7188\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7622 - val_loss: 0.5322 - val_accuracy: 0.7188\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7622 - val_loss: 0.5322 - val_accuracy: 0.7188\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.5321 - val_accuracy: 0.7188\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7622 - val_loss: 0.5320 - val_accuracy: 0.7188\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.5319 - val_accuracy: 0.7188\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7622 - val_loss: 0.5317 - val_accuracy: 0.7188\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7622 - val_loss: 0.5316 - val_accuracy: 0.7188\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.5315 - val_accuracy: 0.7188\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.5315 - val_accuracy: 0.7188\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7622 - val_loss: 0.5314 - val_accuracy: 0.7188\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7622 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7188\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.5311 - val_accuracy: 0.7188\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7622 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.7622 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7188\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7622 - val_loss: 0.5309 - val_accuracy: 0.7188\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7622 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7639 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7639 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7639 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7639 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7639 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4880 - accuracy: 0.7639 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.5299 - val_accuracy: 0.7188\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.5299 - val_accuracy: 0.7188\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7639 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.5296 - val_accuracy: 0.7188\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7639 - val_loss: 0.5296 - val_accuracy: 0.7188\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7622 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7622 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7622 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7622 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7622 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7639 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7639 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7639 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7639 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7639 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7639 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7639 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7188\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7188\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7656 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7656 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7656 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7656 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7656 - val_loss: 0.5274 - val_accuracy: 0.7188\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7656 - val_loss: 0.5274 - val_accuracy: 0.7188\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.5274 - val_accuracy: 0.7188\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7674 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7674 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7674 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7691 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7708 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7708 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5260 - val_accuracy: 0.7135\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5259 - val_accuracy: 0.7135\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7135\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5258 - val_accuracy: 0.7083\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7083\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7083\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7083\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7083\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7083\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7135\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7135\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7083\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7083\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7083\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7083\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7083\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5246 - val_accuracy: 0.7135\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7188\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7188\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5241 - val_accuracy: 0.7188\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5240 - val_accuracy: 0.7188\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7188\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7795 - val_loss: 0.5239 - val_accuracy: 0.7240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_x=model2.predict(X_test)\n",
        "classes_x=np.argmax(predict_x,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMkehAxlNa0P",
        "outputId": "6408fbfb-4ad2-4ee1-e336-637605ad5d74"
      },
      "id": "RMkehAxlNa0P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the model2 is greater than 0.5\n",
        "y_pred_class_nn_2 = (model2.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_2 = model2.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGRQDintNfiV",
        "outputId": "9408809d-72c2-4d10-8deb-57c365ececf8"
      },
      "id": "jGRQDintNfiV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC-AUC Curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "5gFis9ZiGAdK",
        "outputId": "f645d660-5d86-4238-eb64-3f9a6775e60e"
      },
      "id": "5gFis9ZiGAdK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.724\n",
            "roc-auc is 0.803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation Loss\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ngnWKIr-7Ncs",
        "outputId": "bb4c80a6-b456-44f9-ac0d-45f065e469dc"
      },
      "id": "ngnWKIr-7Ncs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f015223b700>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here, I adjusted the neural network by adding more hidden layers with a learning rate of 0.001. Based on the line graph, both the training and validation losses gradually decreased as the number of epochs increased. However, the validation loss increased at 600 epochs, indicating that the data overfitted, but when it reached 800 epochs, it slightly decreased and became stable."
      ],
      "metadata": {
        "id": "vMysMGcuVnjp"
      },
      "id": "vMysMGcuVnjp"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "-\n",
        "In this activity, we are tasked with performing a neural network and making adjustments. Based on what I observed from the procedure and supplementary activities, adjusting the neural network can improve its ability to learn relevant features of the data and optimize generalization to unseen data. However, making adjustments to neural networks requires training time that affects the performance of the data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}